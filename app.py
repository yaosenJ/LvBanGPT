import os
import gradio as gr
import requests
from gradio.components import HTML 
import uuid
from sparkai.core.messages import ChatMessage, AIMessageChunk
from dwspark.config import Config
from dwspark.models import ChatModel, ImageUnderstanding, Text2Audio, Audio2Text, EmbeddingModel
from PIL import Image
import io
import base64
import random
from langchain.vectorstores.chroma import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders.pdf import PyMuPDFLoader
from langchain_community.retrievers import BM25Retriever
from sklearn.metrics.pairwise import cosine_similarity 
import pickle
import FlagEmbedding 
import re
import time
import json
import numpy as np
from text2audio.infer import audio2lip
# æ—¥å¿—
from loguru import logger
from langchain_community.tools.tavily_search import TavilySearchResults
import datetime
from http import HTTPStatus
from dashscope import Generation
import dashscope
from dotenv import load_dotenv, find_dotenv
_ = load_dotenv(find_dotenv())
# åŠ è½½è®¯é£çš„apié…ç½®
SPARKAI_APP_ID = os.getenv("SPARKAI_APP_ID")
SPARKAI_API_SECRET = os.getenv("SPARKAI_API_SECRET")
SPARKAI_API_KEY = os.getenv("SPARKAI_API_KEY")
config = Config(SPARKAI_APP_ID, SPARKAI_API_KEY, SPARKAI_API_SECRET)
dashscope.api_key = os.getenv("dashscope_api_key")
# åˆå§‹åŒ–æ¨¡å‹
iu = ImageUnderstanding(config)
t2a = Text2Audio(config)

# ä¸´æ—¶å­˜å‚¨ç›®å½•
TEMP_IMAGE_DIR = "/tmp/sparkai_images/"
#AUDIO_TEMP_DIR = "/tmp/sparkai_audios/"

style_options = ["æœ‹å‹åœˆ", "å°çº¢ä¹¦", "å¾®åš", "æŠ–éŸ³"]

# ä¿å­˜å›¾ç‰‡å¹¶è·å–ä¸´æ—¶è·¯å¾„
def save_and_get_temp_url(image):
    if not os.path.exists(TEMP_IMAGE_DIR):
        os.makedirs(TEMP_IMAGE_DIR)
    unique_filename = str(uuid.uuid4()) + ".png"
    temp_filepath = os.path.join(TEMP_IMAGE_DIR, unique_filename)
    image.save(temp_filepath)
    return temp_filepath

# ç”Ÿæˆæ–‡æœ¬
def generate_text_from_image(image, style):
    temp_image_path = save_and_get_temp_url(image)
    prompt = "è¯·ç†è§£è¿™å¼ å›¾ç‰‡"
    image_description = iu.understanding(prompt, temp_image_path)
    question = f"æ ¹æ®å›¾ç‰‡æè¿°ï¼š{image_description}, ç”¨{style}é£æ ¼ç”Ÿæˆä¸€æ®µæ–‡å­—ã€‚"
    stream_model = ChatModel(config, stream=False)
    generated_text = stream_model.generate([ChatMessage(role="user", content=question)])
    return generated_text

# æ–‡æ¡ˆåˆ°è¯­éŸ³
def text_to_audio(text_input):
    try:
        audio_path = "./demo.mp3"
        t2a.gen_audio(text_input, audio_path)
        return audio_path
    except Exception as e:
        print(f"Error generating audio: {e}")

# ç¬¬ä¸€é˜¶æ®µï¼šç”¨æˆ·ä¸Šä¼ å›¾ç‰‡å¹¶é€‰æ‹©é£æ ¼åï¼Œç‚¹å‡»ç”Ÿæˆæ–‡æ¡ˆ
def on_generate_click(image, style):
    generated_text = generate_text_from_image(image, style)
    return generated_text

# ç¬¬äºŒé˜¶æ®µï¼šç‚¹å‡»â€œå°†æ–‡æ¡ˆè½¬ä¸ºè¯­éŸ³â€æŒ‰é’®ï¼Œç”Ÿæˆå¹¶æ’­æ”¾è¯­éŸ³
def on_convert_click(text_output):
    return text_to_audio(text_output)

# ç¬¬ä¸‰é˜¶æ®µï¼šç‚¹å‡»â€œå°†æ–‡æ¡ˆè½¬ä¸ºæ•°å­—äººè§†é¢‘â€æŒ‰é’®ï¼Œç”Ÿæˆå¹¶æ’­æ”¾è¯­éŸ³
def on_lip_click(text_output,video_path='./shuziren.mp4'):
    video_output = audio2lip(text_output,video_path)
    return video_output
    
rerank_path = '/mnt/workspace/LvBanGPT/model/rerank_model'
rerank_model_name = 'BAAI/bge-reranker-large'
def extract_cities_from_text(text):
    # ä»æ–‡æœ¬ä¸­æå–åŸå¸‚åç§°ï¼Œå‡è®¾ä½¿ç”¨jiebaè¿›è¡Œåˆ†è¯å’Œæå–åœ°å
    import jieba.posseg as pseg
    words = pseg.cut(text)
    cities = [word for word, flag in words if flag == "ns"]
    return cities

def find_pdfs_with_city(cities, pdf_directory):
    matched_pdfs = {}
    for city in cities:
        matched_pdfs[city] = []
        for root, _, files in os.walk(pdf_directory):
            for file in files:
                if file.endswith(".pdf") and city in file:
                    matched_pdfs[city].append(os.path.join(root, file))
    return matched_pdfs

def get_embedding_pdf(text, pdf_directory):
    # ä»æ–‡æœ¬ä¸­æå–åŸå¸‚åç§°
    cities = extract_cities_from_text(text)
    # æ ¹æ®åŸå¸‚åç§°åŒ¹é…PDFæ–‡ä»¶
    city_to_pdfs = find_pdfs_with_city(cities, pdf_directory)
    return city_to_pdfs


def load_rerank_model(model_name=rerank_model_name):
    """
    åŠ è½½é‡æ’åæ¨¡å‹ã€‚
    
    å‚æ•°:
    - model_name (str): æ¨¡å‹çš„åç§°ã€‚é»˜è®¤ä¸º 'BAAI/bge-reranker-large'ã€‚
    
    è¿”å›:
    - FlagReranker å®ä¾‹ã€‚
    
    å¼‚å¸¸:
    - ValueError: å¦‚æœæ¨¡å‹åç§°ä¸åœ¨æ‰¹å‡†çš„æ¨¡å‹åˆ—è¡¨ä¸­ã€‚
    - Exception: å¦‚æœæ¨¡å‹åŠ è½½è¿‡ç¨‹ä¸­å‘ç”Ÿä»»ä½•å…¶ä»–é”™è¯¯ã€‚
    """ 
    if not os.path.exists(rerank_path):
        os.makedirs(rerank_path, exist_ok=True)
    rerank_model_path = os.path.join(rerank_path, model_name.split('/')[1] + '.pkl')
    #print(rerank_model_path)
    logger.info('Loading rerank model...')
    if os.path.exists(rerank_model_path):
        try:
            with open(rerank_model_path , 'rb') as f:
                reranker_model = pickle.load(f)
                logger.info('Rerank model loaded.')
                return reranker_model
        except Exception as e:
            logger.error(f'Failed to load embedding model from {rerank_model_path}') 
    else:
        try:
            os.system('apt install git')
            os.system('apt install git-lfs')
            os.system(f'git clone https://code.openxlab.org.cn/answer-qzd/bge_rerank.git {rerank_path}')
            os.system(f'cd {rerank_path} && git lfs pull')
            
            with open(rerank_model_path , 'rb') as f:
                reranker_model = pickle.load(f)
                logger.info('Rerank model loaded.')
                return reranker_model
                
        except Exception as e:
            logger.error(f'Failed to load rerank model: {e}')

def rerank(reranker, query, contexts, select_num):
        merge = [[query, context] for context in contexts]
        scores = reranker.compute_score(merge)
        sorted_indices = np.argsort(scores)[::-1]

        return [contexts[i] for i in sorted_indices[:select_num]]

def embedding_make(text_input, pdf_directory):

    city_to_pdfs = get_embedding_pdf(text_input, pdf_directory)
    city_list = []
    for city, pdfs in city_to_pdfs.items():
        print(f"City: {city}")
        for pdf in pdfs:
            city_list.append(pdf)
    
    if len(city_list) != 0:
        # all_pdf_pages = []
        all_text = ''
        for city in city_list:
            from pdf_read import FileOperation
            file_opr = FileOperation()
            try:
                text, error = file_opr.read(city)
            except:
                continue
            all_text += text
            
        pattern = re.compile(r'[^\u4e00-\u9fff](\n)[^\u4e00-\u9fff]', re.DOTALL)
        all_text = re.sub(pattern, lambda match: match.group(0).replace('\n', ''), all_text)

        text_spliter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=300) 
        docs = text_spliter.create_documents([all_text])
        splits = text_spliter.split_documents(docs)
        question=text_input
        
        retriever = BM25Retriever.from_documents(splits)
        retriever.k = 20
        bm25_result = retriever.invoke(question)


        em = EmbeddingModel(config)
        question_vector = em.get_embedding(question)
        pdf_vector_list = []
        
        start_time = time.perf_counter()

        em = EmbeddingModel(config)  
        for i in range(len(bm25_result)):
            x = em.get_embedding(bm25_result[i].page_content) 
            pdf_vector_list.append(x)
            time.sleep(0.65)

        query_embedding = np.array(question_vector)
        query_embedding = query_embedding.reshape(1, -1)

        similarities = cosine_similarity(query_embedding, pdf_vector_list)

        top_k = 10
        top_k_indices = np.argsort(similarities[0])[-top_k:][::-1]

        emb_list = []
        for idx in top_k_indices:
            all_page = splits[idx].page_content
            emb_list.append(all_page)
        print(len(emb_list))

        reranker_model = load_rerank_model()

        documents = rerank(reranker_model, question, emb_list, 3)
        logger.info("After rerank...")
        reranked = []
        for doc in documents:
            reranked.append(doc)
        print(len(reranked))
        reranked = ''.join(reranked)

        model_input = f'ä½ æ˜¯ä¸€ä¸ªæ—…æ¸¸æ”»ç•¥å°åŠ©æ‰‹ï¼Œä½ çš„ä»»åŠ¡æ˜¯ï¼Œæ ¹æ®æ”¶é›†åˆ°çš„ä¿¡æ¯ï¼š\n{reranked}.\næ¥ç²¾å‡†å›ç­”ç”¨æˆ·æ‰€æå‡ºçš„é—®é¢˜ï¼š{question}ã€‚'
        #print(reranked)

        model = ChatModel(config, stream=False)
        output = model.generate([ChatMessage(role="user", content=model_input)])

        return output
    else:
        return "è¯·åœ¨è¾“å…¥ä¸­æåŠæƒ³è¦å’¨è¯¢çš„åŸå¸‚ï¼"

def process_question(history, use_knowledge_base, question, pdf_directory='./dataset'):
    if use_knowledge_base=='æ˜¯':
        response = embedding_make(question, pdf_directory)
    else:
        model = ChatModel(config, stream=False)
        response = model.generate([ChatMessage(role="user", content=question)])
    
    history.append((question, response))
    return "", history

def clear_history(history):
    history.clear()
    return history

# è·å–åŸå¸‚ä¿¡æ¯ 
def get_location_data(location,api_key):  
    """  
    å‘ QWeather API å‘é€ GET è¯·æ±‚ä»¥è·å–å¤©æ°”æ•°æ®ã€‚  
  
    :param location: åœ°ç‚¹åç§°æˆ–ç»çº¬åº¦ï¼ˆä¾‹å¦‚ï¼š"beijing" æˆ– "116.405285,39.904989"ï¼‰  
    :param api_key: ä½ çš„ QWeather API å¯†é’¥  
    :return: å“åº”çš„ JSON æ•°æ®  
    """  
    # æ„å»ºè¯·æ±‚ URL  
    url = f"https://geoapi.qweather.com/v2/city/lookup?location={location}&key={api_key}"  
  
    # å‘é€ GET è¯·æ±‚  
    response = requests.get(url)  
  
    # æ£€æŸ¥å“åº”çŠ¶æ€ç   
    if response.status_code == 200:  
        # è¿”å› JSON æ•°æ®  
        return response.json()
    else:  
        # å¤„ç†é”™è¯¯æƒ…å†µ  
        print(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")  
        print(response.text)  
        return None
    
# è·å–å¤©æ°”  
def get_weather_forecast(location_id,api_key):  
    """  
    å‘QWeather APIå‘é€è¯·æ±‚ä»¥è·å–æœªæ¥å‡ å¤©çš„å¤©æ°”é¢„æŠ¥ã€‚  
  
    å‚æ•°:  
    - location: åœ°ç‚¹IDæˆ–ç»çº¬åº¦  
    - api_key: ä½ çš„QWeather APIå¯†é’¥  
    - duration: é¢„æŠ¥çš„æ—¶é•¿ï¼Œ'3d' æˆ– '7d'  
  
    è¿”å›:  
    - å“åº”çš„JSONå†…å®¹  
    """
    
    # æ„å»ºè¯·æ±‚çš„URL  
    url = f"https://devapi.qweather.com/v7/weather/3d?location={location_id}&key={api_key}"  
  
    # å‘é€GETè¯·æ±‚  
    response = requests.get(url)  
  
    # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ  
    if response.status_code == 200:  
        # è¿”å›å“åº”çš„JSONå†…å®¹  
        return response.json()  
    else:  
        # å¦‚æœè¯·æ±‚ä¸æˆåŠŸï¼Œæ‰“å°é”™è¯¯ä¿¡æ¯  
        print(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}ï¼Œé”™è¯¯ä¿¡æ¯ï¼š{response.text}")  
        return None  
api_key = os.getenv("api_key")
from openai import OpenAI
client = OpenAI(
        api_key=api_key,
        base_url="https://api.deepseek.com"
)

amap_key = os.getenv("amap_key")

def get_completion(messages, model="deepseek-chat"):
    response = client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=0,  # æ¨¡å‹è¾“å‡ºçš„éšæœºæ€§ï¼Œ0 è¡¨ç¤ºéšæœºæ€§æœ€å°
        seed=1024,  # éšæœºç§å­ä¿æŒä¸å˜ï¼Œtemperature å’Œ prompt ä¸å˜çš„æƒ…å†µä¸‹ï¼Œè¾“å‡ºå°±ä¼šä¸å˜
        tool_choice="auto",  # é»˜è®¤å€¼ï¼Œç”±ç³»ç»Ÿè‡ªåŠ¨å†³å®šï¼Œè¿”å›function callè¿˜æ˜¯è¿”å›æ–‡å­—å›å¤
        tools=[{
            "type": "function",
            "function": {

                "name": "get_location_coordinate",
                "description": "æ ¹æ®POIåç§°ï¼Œè·å¾—POIçš„ç»çº¬åº¦åæ ‡",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "location": {
                            "type": "string",
                            "description": "POIåç§°ï¼Œå¿…é¡»æ˜¯ä¸­æ–‡",
                        },
                        "city": {
                            "type": "string",
                            "description": "POIæ‰€åœ¨çš„åŸå¸‚åï¼Œå¿…é¡»æ˜¯ä¸­æ–‡",
                        }
                    },
                    "required": ["location", "city"],
                }
            }
        },
            {
            "type": "function",
            "function": {
                "name": "search_nearby_pois",
                "description": "æœç´¢ç»™å®šåæ ‡é™„è¿‘çš„poi",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "longitude": {
                            "type": "string",
                            "description": "ä¸­å¿ƒç‚¹çš„ç»åº¦",
                        },
                        "latitude": {
                            "type": "string",
                            "description": "ä¸­å¿ƒç‚¹çš„çº¬åº¦",
                        },
                        "keyword": {
                            "type": "string",
                            "description": "ç›®æ ‡poiçš„å…³é”®å­—",
                        }
                    },
                    "required": ["longitude", "latitude", "keyword"],
                }
            }
        }],
    )
    return response.choices[0].message




def get_location_coordinate(location, city):
    url = f"https://restapi.amap.com/v5/place/text?key={amap_key}&keywords={location}&region={city}"
    print(url)
    r = requests.get(url)
    result = r.json()
    if "pois" in result and result["pois"]:
        return result["pois"][0]
    return None


def search_nearby_pois(longitude, latitude, keyword):
    url = f"https://restapi.amap.com/v5/place/around?key={amap_key}&keywords={keyword}&location={longitude},{latitude}"
    print(url)
    r = requests.get(url)
    result = r.json()
    ans = ""
    if "pois" in result and result["pois"]:
        for i in range(min(3, len(result["pois"]))):
            name = result["pois"][i]["name"]
            address = result["pois"][i]["address"]
            distance = result["pois"][i]["distance"]
            ans += f"{name}\n{address}\nè·ç¦»ï¼š{distance}ç±³\n\n"
    return ans
    

def process_request(prompt):
    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªåœ°å›¾é€šï¼Œä½ å¯ä»¥æ‰¾åˆ°ä»»ä½•åœ°å€ã€‚"},
        {"role": "user", "content": prompt}
    ]
    response = get_completion(messages)
    if (response.content is None):  # è§£å†³ OpenAI çš„ä¸€ä¸ª 400 bug
        response.content = ""
    messages.append(response)  # æŠŠå¤§æ¨¡å‹çš„å›å¤åŠ å…¥åˆ°å¯¹è¯ä¸­
    print("=====GPTå›å¤=====")
    print(response)
    
    # å¦‚æœè¿”å›çš„æ˜¯å‡½æ•°è°ƒç”¨ç»“æœï¼Œåˆ™æ‰“å°å‡ºæ¥
    while (response.tool_calls is not None):
        # 1106 ç‰ˆæ–°æ¨¡å‹æ”¯æŒä¸€æ¬¡è¿”å›å¤šä¸ªå‡½æ•°è°ƒç”¨è¯·æ±‚
        for tool_call in response.tool_calls:
            args = json.loads(tool_call.function.arguments)
            print(args)
    
            if (tool_call.function.name == "get_location_coordinate"):
                print("Call: get_location_coordinate")
                result = get_location_coordinate(**args)
            elif (tool_call.function.name == "search_nearby_pois"):
                print("Call: search_nearby_pois")
                result = search_nearby_pois(**args)
    
            print("=====å‡½æ•°è¿”å›=====")
            print(result)
    
            messages.append({
                "tool_call_id": tool_call.id,  # ç”¨äºæ ‡è¯†å‡½æ•°è°ƒç”¨çš„ ID
                "role": "tool",
                "name": tool_call.function.name,
                "content": str(result)  # æ•°å€¼result å¿…é¡»è½¬æˆå­—ç¬¦ä¸²
            })
    
        response = get_completion(messages)
        if (response.content is None):  # è§£å†³ OpenAI çš„ä¸€ä¸ª 400 bug
            response.content = ""
        messages.append(response)  # æŠŠå¤§æ¨¡å‹çš„å›å¤åŠ å…¥åˆ°å¯¹è¯ä¸­
    
    print("=====æœ€ç»ˆå›å¤=====")
    print(response.content)
    return response.content

def llm(query, history=[], user_stop_words=[]):
    try:
        messages = [{'role': 'system', 'content': 'You are a helpful assistant.'}]
        for hist in history:
            messages.append({'role': 'user', 'content': hist[0]})
            messages.append({'role': 'assistant', 'content': hist[1]})
        messages.append({'role': 'user', 'content': query})
        responses = Generation.call(
            model="qwen1.5-110b-chat",
            messages=messages,
            result_format='message',
            stream=True,
            incremental_output=True
        )
        content = ""
        for response in responses:
            if response.status_code == HTTPStatus.OK:
                print(response)
                content += response.output.choices[0].message.content
            else:
                print('Request id: %s, Status code: %s, error code: %s, error message: %s' % (
                    response.request_id, response.status_code,
                    response.code, response.message
                ))
        return content
    except Exception as e:
        return str(e)

# Travily æœç´¢å¼•æ“
os.environ['TAVILY_API_KEY'] = os.getenv("TAVILY_API_KEY")
tavily = TavilySearchResults(max_results=5)
tavily.description = 'è¿™æ˜¯ä¸€ä¸ªç±»ä¼¼è°·æ­Œå’Œç™¾åº¦çš„æœç´¢å¼•æ“ï¼Œæœç´¢çŸ¥è¯†ã€å¤©æ°”ã€è‚¡ç¥¨ã€ç”µå½±ã€å°è¯´ã€ç™¾ç§‘ç­‰éƒ½æ˜¯æ”¯æŒçš„å“¦ï¼Œå¦‚æœä½ ä¸ç¡®å®šå°±åº”è¯¥æœç´¢ä¸€ä¸‹ï¼Œè°¢è°¢ï¼'

# å·¥å…·åˆ—è¡¨
tools = [tavily]

tool_names = 'or'.join([tool.name for tool in tools])
tool_descs = []
for t in tools:
    args_desc = []
    for name, info in t.args.items():
        args_desc.append({'name': name, 'description': info['description'] if 'description' in info else '', 'type': info['type']})
    args_desc = json.dumps(args_desc, ensure_ascii=False)
    tool_descs.append('%s: %s,args: %s' % (t.name, t.description, args_desc))
tool_descs = '\n'.join(tool_descs)

prompt_tpl = '''Today is {today}. Please Answer the following questions as best you can. You have access to the following tools:

{tool_descs}

These are chat history before:
{chat_history}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can be repeated zero or more times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!

Question: {query}
{agent_scratchpad}
'''

def agent_execute(query, chat_history=[]):
    global tools, tool_names, tool_descs, prompt_tpl, llm, tokenizer
    
    agent_scratchpad = ''  # agentæ‰§è¡Œè¿‡ç¨‹
    while True:
        history = '\n'.join(['Question:%s\nAnswer:%s' % (his[0], his[1]) for his in chat_history])
        today = datetime.datetime.now().strftime('%Y-%m-%d')
        prompt = prompt_tpl.format(today=today, chat_history=history, tool_descs=tool_descs, tool_names=tool_names, query=query, agent_scratchpad=agent_scratchpad)
        print('\033[32m---ç­‰å¾…LLMè¿”å›... ...\n%s\n\033[0m' % prompt, flush=True)

        response = llm(prompt, user_stop_words=['Observation:'])
        print('\033[34m---LLMè¿”å›---\n%s\n---\033[34m' % response, flush=True)
        
        thought_i = response.rfind('Thought:')
        final_answer_i = response.rfind('\nFinal Answer:')
        action_i = response.rfind('\nAction:')
        action_input_i = response.rfind('\nAction Input:')
        observation_i = response.rfind('\nObservation:')
        
        if final_answer_i != -1 and thought_i < final_answer_i:
            final_answer = response[final_answer_i + len('\nFinal Answer:'):].strip()
            chat_history.append((query, final_answer))
            return True, final_answer, chat_history
        
        if not (thought_i < action_i < action_input_i):
            return False, 'LLMå›å¤æ ¼å¼å¼‚å¸¸', chat_history
        if observation_i == -1:
            observation_i = len(response)
            response = response + 'Observation: '
        thought = response[thought_i + len('Thought:'):action_i].strip()
        action = response[action_i + len('\nAction:'):action_input_i].strip()
        action_input = response[action_input_i + len('\nAction Input:'):observation_i].strip()
        
        the_tool = None
        for t in tools:
            if t.name == action:
                the_tool = t
                break
        if the_tool is None:
            observation = 'the tool not exist'
            agent_scratchpad = agent_scratchpad + response + observation + '\n'
            continue 
        
        try:
            action_input = json.loads(action_input)
            tool_ret = the_tool.invoke(input=json.dumps(action_input))
        except Exception as e:
            observation = 'the tool has error:{}'.format(e)
        else:
            observation = str(tool_ret)
        agent_scratchpad = agent_scratchpad + response + observation + '\n'

def agent_execute_with_retry(query, chat_history=[], retry_times=10):
    for i in range(retry_times):
        success, result, chat_history = agent_execute(query, chat_history=chat_history)
        if success:
            return success, result, chat_history
    return success, result, chat_history

def process_network(query):
    my_history = []
    success, result, my_history = agent_execute_with_retry(query, chat_history=my_history)
    return result

# æ—…è¡Œè§„åˆ’å¸ˆåŠŸèƒ½

prompt = """ä½ ç°åœ¨æ˜¯ä¸€ä½ä¸“ä¸šçš„æ—…è¡Œè§„åˆ’å¸ˆï¼Œä½ çš„è´£ä»»æ˜¯æ ¹æ®æ—…è¡Œå‡ºå‘åœ°ã€ç›®çš„åœ°ã€å¤©æ•°ã€è¡Œç¨‹é£æ ¼ï¼ˆç´§å‡‘ã€é€‚ä¸­ã€ä¼‘é—²ï¼‰ã€é¢„ç®—ã€éšè¡Œäººæ•°ï¼Œå¸®åŠ©æˆ‘è§„åˆ’æ—…æ¸¸è¡Œç¨‹å¹¶ç”Ÿæˆè¯¦ç»†çš„æ—…è¡Œè®¡åˆ’è¡¨ã€‚è¯·ä½ ä»¥è¡¨æ ¼çš„æ–¹å¼å‘ˆç°ç»“æœã€‚æ—…è¡Œè®¡åˆ’è¡¨çš„è¡¨å¤´è¯·åŒ…å«æ—¥æœŸã€åœ°ç‚¹ã€è¡Œç¨‹è®¡åˆ’ã€äº¤é€šæ–¹å¼ã€é¤é¥®å®‰æ’ã€ä½å®¿å®‰æ’ã€è´¹ç”¨ä¼°ç®—ã€å¤‡æ³¨ã€‚æ‰€æœ‰è¡¨å¤´éƒ½ä¸ºå¿…å¡«é¡¹ï¼Œè¯·åŠ æ·±æ€è€ƒè¿‡ç¨‹ï¼Œä¸¥æ ¼éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š

1. æ—¥æœŸè¯·ä»¥DayNä¸ºæ ¼å¼å¦‚Day1ï¼Œæ˜ç¡®æ ‡è¯†æ¯å¤©çš„è¡Œç¨‹ã€‚
2. åœ°ç‚¹éœ€è¦å‘ˆç°å½“å¤©æ‰€åœ¨åŸå¸‚ï¼Œè¯·æ ¹æ®æ—¥æœŸã€è€ƒè™‘åœ°ç‚¹çš„åœ°ç†ä½ç½®è¿œè¿‘ï¼Œä¸¥æ ¼ä¸”åˆç†åˆ¶å®šåœ°ç‚¹ï¼Œç¡®ä¿è¡Œç¨‹é¡ºç•…ã€‚
3. è¡Œç¨‹è®¡åˆ’éœ€åŒ…å«ä½ç½®ã€æ—¶é—´ã€æ´»åŠ¨ï¼Œå…¶ä¸­ä½ç½®éœ€è¦æ ¹æ®åœ°ç†ä½ç½®çš„è¿œè¿‘è¿›è¡Œæ’åºã€‚ä½ç½®çš„æ•°é‡å¯ä»¥æ ¹æ®è¡Œç¨‹é£æ ¼çµæ´»è°ƒæ•´ï¼Œå¦‚ä¼‘é—²åˆ™ä½ç½®æ•°é‡è¾ƒå°‘ã€ç´§å‡‘åˆ™ä½ç½®æ•°é‡è¾ƒå¤šã€‚æ—¶é—´éœ€è¦æŒ‰ç…§ä¸Šåˆã€ä¸­åˆã€æ™šä¸Šåˆ¶å®šï¼Œå¹¶ç»™å‡ºæ¯ä¸€ä¸ªä½ç½®æ‰€åœç•™çš„æ—¶é—´ï¼ˆå¦‚ä¸Šåˆ10ç‚¹-ä¸­åˆ12ç‚¹ï¼‰ã€‚æ´»åŠ¨éœ€è¦å‡†ç¡®æè¿°åœ¨ä½ç½®å‘ç”Ÿçš„å¯¹åº”æ´»åŠ¨ï¼ˆå¦‚å‚è§‚åšç‰©é¦†ã€æ¸¸è§ˆå…¬å›­ã€åƒé¥­ç­‰ï¼‰ï¼Œå¹¶éœ€æ ¹æ®ä½ç½®åœç•™æ—¶é—´åˆç†å®‰æ’æ´»åŠ¨ç±»å‹ã€‚
4. äº¤é€šæ–¹å¼éœ€æ ¹æ®åœ°ç‚¹ã€è¡Œç¨‹è®¡åˆ’ä¸­çš„æ¯ä¸ªä½ç½®çš„åœ°ç†è·ç¦»åˆç†é€‰æ‹©ï¼Œå¦‚æ­¥è¡Œã€åœ°é“ã€å‡ºç§Ÿè½¦ã€ç«è½¦ã€é£æœºç­‰ä¸åŒçš„äº¤é€šæ–¹å¼ï¼Œå¹¶å°½å¯èƒ½è¯¦ç»†è¯´æ˜ã€‚
5. é¤é¥®å®‰æ’éœ€åŒ…å«æ¯é¤çš„æ¨èé¤å…ã€ç±»å‹ï¼ˆå¦‚æœ¬åœ°ç‰¹è‰²ã€å¿«é¤ç­‰ï¼‰ã€é¢„ç®—èŒƒå›´ï¼Œå°±è¿‘é€‰æ‹©ã€‚
6. ä½å®¿å®‰æ’éœ€åŒ…å«æ¯æ™šçš„æ¨èé…’åº—æˆ–ä½å®¿ç±»å‹ï¼ˆå¦‚é…’åº—ã€æ°‘å®¿ç­‰ï¼‰ã€åœ°å€ã€é¢„ä¼°è´¹ç”¨ï¼Œå°±è¿‘é€‰æ‹©ã€‚
7. è´¹ç”¨ä¼°ç®—éœ€åŒ…å«æ¯å¤©çš„é¢„ä¼°æ€»è´¹ç”¨ï¼Œå¹¶æ³¨æ˜å„é¡¹è´¹ç”¨çš„ç»†åˆ†ï¼ˆå¦‚äº¤é€šè´¹ã€é¤é¥®è´¹ã€é—¨ç¥¨è´¹ç­‰ï¼‰ã€‚
8. å¤‡æ³¨ä¸­éœ€è¦åŒ…æ‹¬å¯¹åº”è¡Œç¨‹è®¡åˆ’éœ€è¦è€ƒè™‘åˆ°çš„æ³¨æ„äº‹é¡¹ï¼Œä¿æŒå¤šæ ·æ€§ï¼Œæ¶‰åŠé¥®é£Ÿã€æ–‡åŒ–ã€å¤©æ°”ã€è¯­è¨€ç­‰æ–¹é¢çš„æé†’ã€‚
9. è¯·ç‰¹åˆ«è€ƒè™‘éšè¡Œäººæ•°çš„ä¿¡æ¯ï¼Œç¡®ä¿è¡Œç¨‹å’Œä½å®¿å®‰æ’èƒ½æ»¡è¶³æ‰€æœ‰éšè¡Œäººå‘˜çš„éœ€æ±‚ã€‚
10.æ—…æ¸¸æ€»ä½“è´¹ç”¨ä¸èƒ½è¶…è¿‡é¢„ç®—ã€‚

ç°åœ¨è¯·ä½ ä¸¥æ ¼éµå®ˆä»¥ä¸Šè§„åˆ™ï¼Œæ ¹æ®æˆ‘çš„æ—…è¡Œå‡ºå‘åœ°ã€ç›®çš„åœ°ã€å¤©æ•°ã€è¡Œç¨‹é£æ ¼ï¼ˆç´§å‡‘ã€é€‚ä¸­ã€ä¼‘é—²ï¼‰ã€é¢„ç®—ã€éšè¡Œäººæ•°ï¼Œç”Ÿæˆåˆç†ä¸”è¯¦ç»†çš„æ—…è¡Œè®¡åˆ’è¡¨ã€‚è®°ä½ä½ è¦æ ¹æ®æˆ‘æä¾›çš„æ—…è¡Œç›®çš„åœ°ã€å¤©æ•°ç­‰ä¿¡æ¯ä»¥è¡¨æ ¼å½¢å¼ç”Ÿæˆæ—…è¡Œè®¡åˆ’è¡¨ï¼Œæœ€ç»ˆç­”æ¡ˆä¸€å®šæ˜¯è¡¨æ ¼å½¢å¼ã€‚ä»¥ä¸‹æ˜¯æ—…è¡Œçš„åŸºæœ¬ä¿¡æ¯ï¼š
æ—…æ¸¸å‡ºå‘åœ°ï¼š{}ï¼Œæ—…æ¸¸ç›®çš„åœ°ï¼š{} ï¼Œå¤©æ•°ï¼š{}å¤© ï¼Œè¡Œç¨‹é£æ ¼ï¼š{} ï¼Œé¢„ç®—ï¼š{}ï¼Œéšè¡Œäººæ•°ï¼š{}, ç‰¹æ®Šåå¥½ã€è¦æ±‚ï¼š{}

"""
def chat(chat_destination, chat_history, chat_departure, chat_days, chat_style, chat_budget, chat_people, chat_other):
    stream_model = ChatModel(config, stream=True)
    final_query = prompt.format(chat_departure, chat_destination, chat_days, chat_style, chat_budget,  chat_people, chat_other)
    prompts = [ChatMessage(role='user', content=final_query)]
    # å°†é—®é¢˜è®¾ä¸ºå†å²å¯¹è¯
    chat_history.append((chat_destination, ''))
    # å¯¹è¯åŒæ—¶æµå¼è¿”å›
    for chunk_text in stream_model.generate_stream(prompts):
        # æ€»ç»“ç­”æ¡ˆ
        answer = chat_history[-1][1] + chunk_text
        # æ›¿æ¢æœ€æ–°çš„å¯¹è¯å†…å®¹
        information = 'æ—…æ¸¸å‡ºå‘åœ°ï¼š{}ï¼Œæ—…æ¸¸ç›®çš„åœ°ï¼š{} ï¼Œå¤©æ•°ï¼š{} ï¼Œè¡Œç¨‹é£æ ¼ï¼š{} ï¼Œé¢„ç®—ï¼š{}ï¼Œéšè¡Œäººæ•°ï¼š{}'.format(chat_departure, chat_destination, chat_days, chat_style, chat_budget,  chat_people)
        chat_history[-1] = (information, answer)
        # è¿”å›
        yield '', chat_history

# Gradioæ¥å£å®šä¹‰
with gr.Blocks() as demo:
    html_code = """
        <!DOCTYPE html>
        <html lang="zh-CN">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <style>
                body {
                    font-family: 'Arial', sans-serif;
                    background-color: #f8f9fa;
                    margin: 0;
                    padding: 10px;
                }
                .container {
                    max-width: 1500px;
                    margin: auto;
                    background-color: #ffffff;
                    border-radius: 10px;
                    box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
                    padding: 10px;
                }
                .logo img {
                    display: block;
                    margin: 0 auto;
                    border-radius: 7px;
                }
                .content h2 {
                    text-align: center;
                    color: #999999;
                    font-size: 24px;
                    margin-top: 20px;
                }
                .content p {
                    text-align: center;
                    color: #cccccc;
                    font-size: 16px;
                    line-height: 1.5;
                    margin-top: 30px;
                }
            </style>
        </head>
        <body>
            <div class="container">
                <div class="logo">
                    <img src="https://github.com/yaosenJ/LvBanGPT/blob/main/logo.png?raw=true" alt="Logo" width="30%">
                </div>
                <div class="content">
                    <h2>ğŸ˜€ äº²çˆ±çš„æ—…æ¸¸çˆ±å¥½è€…ä»¬ï¼Œæ¬¢è¿æ¥åˆ°â€œLvBanæ£è¡Œâ€ï¼Œæ‚¨çš„ä¸“å±æ—…è¡Œä¼™ä¼´ï¼æˆ‘ä»¬è‡´åŠ›äºä¸ºæ‚¨æä¾›ä¸ªæ€§åŒ–çš„æ—…è¡Œè§„åˆ’ã€é™ªä¼´å’Œåˆ†äº«æœåŠ¡ï¼Œè®©æ‚¨çš„æ—…ç¨‹å……æ»¡ä¹è¶£å¹¶ç•™ä¸‹éš¾å¿˜å›å¿†ã€‚</h2>
                <div class="hint" style="text-align: center;background-color: rgba(255, 255, 0, 0.15); padding: 10px; margin: 10px; border-radius: 5px; border: 1px solid #ffcc00;">
                    <p>â€œLvBanæ£è¡Œâ€åŸºäºæ˜Ÿç«å¤§æ¨¡å‹çš„æ–‡ç”Ÿæ–‡ã€å›¾ç”Ÿæ–‡ä»¥åŠæ–‡ç”Ÿè¯­éŸ³ç­‰æŠ€æœ¯ï¼Œæ—¨åœ¨ä¸ºæ‚¨é‡èº«å®šåˆ¶ä¸€ä»½æ»¡æ„çš„æ—…è¡Œè®¡åˆ’ã€‚æ— è®ºæ‚¨æœŸæœ›ä½“éªŒä½•ç§æ—…è¡Œç›®çš„åœ°ã€å¤©æ•°ã€è¡Œç¨‹é£æ ¼ï¼ˆå¦‚ç´§å‡‘ã€é€‚ä¸­æˆ–ä¼‘é—²ï¼‰ã€é¢„ç®—ä»¥åŠéšè¡Œäººæ•°ï¼Œæˆ‘ä»¬çš„åŠ©æ‰‹éƒ½èƒ½ä¸ºæ‚¨ç²¾å¿ƒè§„åˆ’è¡Œç¨‹å¹¶ç”Ÿæˆè¯¦å°½çš„æ—…è¡Œè®¡åˆ’è¡¨ï¼ŒåŒ…æ‹¬æ¯å¤©çš„è¡Œç¨‹å®‰æ’ã€äº¤é€šæ–¹å¼ä»¥åŠéœ€è¦æ³¨æ„çš„äº‹é¡¹ã€‚</p>
                    <p>æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜é‡‡ç”¨RAGæŠ€æœ¯ï¼Œä¸“ä¸ºæä¾›å®ç”¨å…¨æ–¹ä½ä¿¡æ¯è€Œè®¾è®¡ï¼ŒåŒ…æ‹¬æ™¯ç‚¹æ¨èã€æ´»åŠ¨å®‰æ’ã€é¤é¥®ã€ä½å®¿ã€è´­ç‰©ã€è¡Œç¨‹æ¨èä»¥åŠå®ç”¨å°è´´å£«ç­‰ã€‚ç›®å‰ï¼Œæˆ‘ä»¬çš„çŸ¥è¯†åº“å·²æ¶µç›–å…¨å›½å„åœ°åŒºã€åŸå¸‚çš„æ—…æ¸¸æ”»ç•¥ä¿¡æ¯ï¼Œä¸ºæ‚¨æä¾›ä¸°å¯Œå¤šæ ·çš„æ—…è¡Œå»ºè®®ã€‚</p>
                    <p>æ‚¨è¿˜å¯ä»¥éšæ—¶æ‹æ‘„æ—…é€”ä¸­çš„ç…§ç‰‡ï¼Œå¹¶é€šè¿‡æˆ‘ä»¬çš„åº”ç”¨ä¸Šä¼ ã€‚åº”ç”¨å°†è‡ªåŠ¨ä¸ºæ‚¨ç”Ÿæˆé€‚åº”ä¸åŒç¤¾äº¤åª’ä½“å¹³å°ï¼ˆå¦‚æœ‹å‹åœˆã€å°çº¢ä¹¦ã€æŠ–éŸ³ã€å¾®åšï¼‰çš„æ–‡æ¡ˆé£æ ¼ï¼Œè®©æ‚¨è½»æ¾åˆ†äº«æ—…é€”ä¸­çš„ç‚¹æ»´ï¼Œä¸æœ‹å‹ä»¬å…±åŒæ„Ÿå—æ—…æ¸¸çš„ä¹è¶£ã€‚</p>
                    <p>ç«‹å³åŠ å…¥â€œLvBanæ£è¡Œâ€ï¼Œè®©æˆ‘ä»¬ä¸ºæ‚¨çš„æ—…è¡Œä¿é©¾æŠ¤èˆªï¼Œå…±åŒæ‰“é€ ä¸€æ®µéš¾å¿˜çš„æ—…ç¨‹ï¼</p>
                </div>
                </div>
            </div>
        </body>
        </html>
"""
    gr.HTML(html_code)
    with gr.Tab("æ—…è¡Œè§„åˆ’åŠ©æ‰‹"):
         # è¾“å…¥æ¡†
        chat_departure = gr.Textbox(label="è¾“å…¥æ—…æ¸¸å‡ºå‘åœ°", placeholder="è¯·ä½ è¾“å…¥å‡ºå‘åœ°")
        chat_destination = gr.Textbox(label="è¾“å…¥æ—…æ¸¸ç›®çš„åœ°", placeholder="è¯·ä½ è¾“å…¥æƒ³å»çš„åœ°æ–¹")
        
        with gr.Accordion("ä¸ªæ€§åŒ–é€‰æ‹©ï¼ˆå¤©æ•°ï¼Œè¡Œç¨‹é£æ ¼ï¼Œé¢„ç®—ï¼Œéšè¡Œäººæ•°ï¼‰", open=False):
            chat_days = gr.Slider(minimum=1, maximum=10, step=1, value=3, label='æ—…æ¸¸å¤©æ•°')
            chat_style = gr.Radio(choices=['ç´§å‡‘', 'é€‚ä¸­', 'ä¼‘é—²'], value='é€‚ä¸­', label='è¡Œç¨‹é£æ ¼')
            chat_budget = gr.Textbox(label="è¾“å…¥é¢„ç®—(å¸¦ä¸Šå•ä½)", placeholder="è¯·ä½ è¾“å…¥é¢„ç®—")
            chat_people = gr.Textbox(label="è¾“å…¥éšè¡Œäººæ•°", placeholder="è¯·ä½ è¾“å…¥éšè¡Œäººæ•°")
            chat_other = gr.Textbox(label="ç‰¹æ®Šåå¥½ã€è¦æ±‚(å¯å†™æ— )", placeholder="è¯·ä½ ç‰¹æ®Šåå¥½ã€è¦æ±‚")
        # èŠå¤©å¯¹è¯æ¡†
        chatbot = gr.Chatbot([], elem_id="chat-box", label="èŠå¤©çª—å£", height=1000)
        # æŒ‰é’®
        llm_submit_tab = gr.Button("å‘é€", visible=True)
        # é—®é¢˜æ ·ä¾‹
        gr.Examples(["åˆè‚¥", "éƒ‘å·", "è¥¿å®‰", "åŒ—äº¬", "å¹¿å·", "å¤§è¿"], chat_departure)
        gr.Examples(["åŒ—äº¬", "å—äº¬", "å¤§ç†", "ä¸Šæµ·", "ä¸œäº¬", "å·´é»"], chat_destination)
        # æŒ‰é’®å‡ºå‘é€»è¾‘
        llm_submit_tab.click(fn=chat, inputs=[chat_destination, chatbot, chat_departure, chat_days, chat_style, chat_budget, chat_people, chat_other], outputs=[ chat_destination,chatbot])
        
    with gr.Tab("æ—…æ¸¸é—®ç­”åŠ©æ‰‹"):
        chatbot = gr.Chatbot(label="èŠå¤©è®°å½•")
        msg = gr.Textbox(lines=2,placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼ˆæ—…æ¸¸æ™¯ç‚¹ã€æ´»åŠ¨ã€é¤é¥®ã€ä½å®¿ã€è´­ç‰©ã€æ¨èè¡Œç¨‹ã€å°è´´å£«ç­‰å®ç”¨ä¿¡æ¯ï¼‰",label="æä¾›æ™¯ç‚¹æ¨èã€æ´»åŠ¨å®‰æ’ã€é¤é¥®ã€ä½å®¿ã€è´­ç‰©ã€è¡Œç¨‹æ¨èã€å®ç”¨å°è´´å£«ç­‰å®ç”¨ä¿¡æ¯")
        whether_rag = gr.Radio(choices=['æ˜¯','å¦'], value='å¦', label='æ˜¯å¦å¯ç”¨RAG')
        submit_button = gr.Button("å‘é€")
        clear_button = gr.Button("æ¸…é™¤å¯¹è¯")
        # é—®é¢˜æ ·ä¾‹
        gr.Examples(["æˆ‘æƒ³å»é¦™æ¸¯ç©ï¼Œä½ æœ‰ä»€ä¹ˆæ¨èçš„å—ï¼Ÿ","æˆ‘è®¡åˆ’æš‘å‡å¸¦å®¶äººå»äº‘å—æ—…æ¸¸ï¼Œè¯·é—®æœ‰å“ªäº›å¿…æ¸¸çš„è‡ªç„¶é£å…‰å’Œæ°‘æ—æ–‡åŒ–æ™¯ç‚¹ï¼Ÿ","ä¸‹ä¸ªæœˆæˆ‘å°†åœ¨è¥¿å®‰ï¼Œæƒ³äº†è§£ç§¦å§‹çš‡å…µé©¬ä¿‘å¼€é€šæ—¶é—´ä»¥åŠäº¤é€šä¿¡æ¯","ç¬¬ä¸€æ¬¡å»è¥¿è—æ—…æ¸¸ï¼Œéœ€è¦æ³¨æ„å“ªäº›é«˜åŸååº”çš„é¢„é˜²æªæ–½ï¼Ÿ","å»ä¸‰äºšåº¦å‡ï¼Œæƒ³è¦ä½æµ·æ™¯é…’åº—ï¼Œæ€§ä»·æ¯”é«˜çš„é€‰æ‹©æœ‰å“ªäº›ï¼Ÿ","å»æ¾³é—¨æ—…æ¸¸çš„æœ€ä½³æ—¶é—´æ˜¯ä»€ä¹ˆæ—¶å€™ï¼Ÿ","è®¡åˆ’ä¸€æ¬¡äº”å¤©å››å¤œçš„è¥¿å®‰æ·±åº¦æ¸¸ï¼Œæ€æ ·å®‰æ’è¡Œç¨‹æ¯”è¾ƒåˆç†ï¼Œèƒ½è¦†ç›–ä¸»è¦æ™¯ç‚¹ï¼Ÿ","åœ¨æ­å·ï¼Œå“ªäº›å®¶é¤é¦†å¯ä»¥æ¨èå»çš„ï¼Ÿ"], msg)
        def respond(message, chat_history, use_kb):
            return process_question(chat_history, use_kb, message)

        def clear_chat(chat_history):
            return clear_history(chat_history)

        submit_button.click(respond, [msg, chatbot, whether_rag], [msg, chatbot])
        clear_button.click(clear_chat, chatbot, chatbot)
        weather_input = gr.Textbox(label="è¯·è¾“å…¥åŸå¸‚åæŸ¥è¯¢å¤©æ°”", placeholder="ä¾‹å¦‚ï¼šåŒ—äº¬")
        weather_output = gr.HTML(value="", label="å¤©æ°”æŸ¥è¯¢ç»“æœ")
        query_button = gr.Button("æŸ¥è¯¢å¤©æ°”")
        query_near = gr.Textbox(label="æœç´¢é™„è¿‘çš„é¤é¥®ã€é…’åº—ç­‰", placeholder="ä¾‹å¦‚ï¼šåˆè‚¥å¸‚é«˜æ–°åŒºä¸­å›½å£°è°·äº§ä¸šå›­é™„è¿‘çš„ç¾é£Ÿ")
        result = gr.Textbox(label="æŸ¥è¯¢ç»“æœ", lines=10)
        submit_btn = gr.Button("æŸ¥è¯¢é™„è¿‘çš„é¤é¥®ã€é…’åº—ç­‰")
        gr.Examples(["åˆè‚¥å¸‚é«˜æ–°åŒºä¸­å›½å£°è°·äº§ä¸šå›­é™„è¿‘çš„ç¾é£Ÿ", "åŒ—äº¬ä¸‰é‡Œå±¯é™„è¿‘çš„å’–å•¡", "å—äº¬å¸‚ç„æ­¦åŒºæ–°è¡—å£é™„è¿‘çš„ç”œå“åº—", "ä¸Šæµ·æµ¦ä¸œæ–°åŒºé™†å®¶å˜´é™„è¿‘çš„çƒ­é—¨é¤å…", "æ­¦æ±‰å¸‚å…‰è°·æ­¥è¡Œè¡—é™„è¿‘çš„ç«é”…åº—", "å¹¿å·å¸‚å¤©æ²³åŒºç æ±Ÿæ–°åŸé™„è¿‘çš„é…’åº—"], query_near)
        submit_btn.click(process_request, inputs=[query_near], outputs=[result])
        
        query_network = gr.Textbox(label="è”ç½‘æœç´¢é—®é¢˜", placeholder="ä¾‹å¦‚ï¼šç§¦å§‹çš‡å…µé©¬ä¿‘å¼€æ”¾æ—¶é—´")
        result_network = gr.Textbox(label="æœç´¢ç»“æœ", lines=10)
        submit_btn_network = gr.Button("è”ç½‘æœç´¢")
        gr.Examples(["ç§¦å§‹çš‡å…µé©¬ä¿‘å¼€æ”¾æ—¶é—´", "åˆè‚¥æœ‰å“ªäº›ç¾é£Ÿ", "åŒ—äº¬æ•…å®«å¼€æ”¾æ—¶é—´", "é»„å±±æ™¯ç‚¹ä»‹ç»", "ä¸Šæµ·è¿ªå£«å°¼é—¨ç¥¨éœ€è¦å¤šå°‘é’±"], query_network)
        submit_btn_network.click(process_network, inputs=[query_network], outputs=[result_network])
        
        Weather_APP_KEY = os.getenv("Weather_APP_KEY")
        def weather_process(location):
                api_key = Weather_APP_KEY  # æ›¿æ¢æˆä½ çš„APIå¯†é’¥  
                location_data = get_location_data(location, api_key)
                # print(location_data)
                if not location_data:
                    return "æ— æ³•è·å–åŸå¸‚ä¿¡æ¯ï¼Œè¯·æ£€æŸ¥æ‚¨çš„è¾“å…¥ã€‚"
                location_id = location_data.get('location', [{}])[0].get('id')
                # print(location_id)
                if not location_id:
                    return "æ— æ³•ä»åŸå¸‚ä¿¡æ¯ä¸­è·å–IDã€‚"
                weather_data = get_weather_forecast(location_id, api_key)
                if not weather_data or weather_data.get('code') != '200':
                    return "æ— æ³•è·å–å¤©æ°”é¢„æŠ¥ï¼Œè¯·æ£€æŸ¥æ‚¨çš„è¾“å…¥å’ŒAPIå¯†é’¥ã€‚"
                # æ„å»ºHTMLè¡¨æ ¼æ¥å±•ç¤ºå¤©æ°”æ•°æ®
                html_content = "<table>"
                html_content += "<tr>"
                html_content += "<th>é¢„æŠ¥æ—¥æœŸ</th>"
                html_content += "<th>ç™½å¤©å¤©æ°”</th>"
                html_content += "<th>å¤œé—´å¤©æ°”</th>"
                html_content += "<th>æœ€é«˜æ¸©åº¦</th>"
                html_content += "<th>æœ€ä½æ¸©åº¦</th>"
                html_content += "<th>ç™½å¤©é£å‘</th>"
                html_content += "<th>ç™½å¤©é£åŠ›ç­‰çº§</th>"
                html_content += "<th>ç™½å¤©é£é€Ÿ</th>"
                html_content += "<th>å¤œé—´é£å‘</th>"
                html_content += "<th>å¤œé—´é£åŠ›ç­‰çº§</th>"
                html_content += "<th>å¤œé—´é£é€Ÿ</th>"
                html_content += "<th>æ€»é™æ°´é‡</th>"
                html_content += "<th>ç´«å¤–çº¿å¼ºåº¦</th>"
                html_content += "<th>ç›¸å¯¹æ¹¿åº¦</th>"
                html_content += "</tr>"

                for day in weather_data.get('daily', []):
                    html_content += f"<tr>"
                    html_content += f"<td>{day['fxDate']}</td>"
                    html_content += f"<td>{day['textDay']} ({day['iconDay']})</td>"
                    html_content += f"<td>{day['textNight']} ({day['iconNight']})</td>"
                    html_content += f"<td>{day['tempMax']}Â°C</td>"
                    html_content += f"<td>{day['tempMin']}Â°C</td>"
                    html_content += f"<td>{day.get('windDirDay', 'æœªçŸ¥')}</td>"
                    html_content += f"<td>{day.get('windScaleDay', 'æœªçŸ¥')}</td>"
                    html_content += f"<td>{day.get('windSpeedDay', 'æœªçŸ¥')} km/h</td>"
                    html_content += f"<td>{day.get('windDirNight', 'æœªçŸ¥')}</td>"
                    html_content += f"<td>{day.get('windScaleNight', 'æœªçŸ¥')}</td>"
                    html_content += f"<td>{day.get('windSpeedNight', 'æœªçŸ¥')} km/h</td>"
                    html_content += f"<td>{day.get('precip', 'æœªçŸ¥')} mm</td>"
                    html_content += f"<td>{day.get('uvIndex', 'æœªçŸ¥')}</td>"
                    html_content += f"<td>{day.get('humidity', 'æœªçŸ¥')}%</td>"
                    html_content += "</tr>"
                html_content += "</table>"  
  
                return HTML(html_content)  
        query_button.click(weather_process, [weather_input], [weather_output])
    

    with gr.Tab("æ—…è¡Œæ–‡æ¡ˆåŠ©æ‰‹"):
        with gr.Row():
            image_input = gr.Image(type="pil", label="ä¸Šä¼ å›¾åƒ")
            style_dropdown = gr.Dropdown(choices=style_options, label="é€‰æ‹©é£æ ¼æ¨¡å¼", value="æœ‹å‹åœˆ")
            audio_output = gr.Audio(label="éŸ³é¢‘æ’­æ”¾", interactive=False, visible=True)
            video_output = gr.Video(label="æ•°å­—äºº",visible=True)

        with gr.Column():
            generate_button = gr.Button("ç”Ÿæˆæ–‡æ¡ˆ", visible=True)
            generated_text = gr.Textbox(lines=8, label="ç”Ÿæˆçš„æ–‡æ¡ˆ", visible=True)
                     
        generate_button.click(on_generate_click, inputs=[image_input, style_dropdown], outputs=[generated_text])
        convert_button1 = gr.Button("å°†æ–‡æ¡ˆè½¬ä¸ºè¯­éŸ³", visible=True)
        convert_button1.click(on_convert_click, inputs=[generated_text], outputs=[audio_output])
        convert_button2 = gr.Button("å°†æ–‡æ¡ˆè½¬ä¸ºè§†é¢‘(è¯·è€å¿ƒç­‰å¾…)", visible=True)
        convert_button2.click(on_lip_click, inputs=[generated_text],outputs=[video_output])

# if __name__ == "__main__":
#     print("å¯åŠ¨ Gradio ç•Œé¢...")
#     demo.queue()  # å¯ç”¨é˜Ÿåˆ—å¤„ç†è¯·æ±‚
#     demo.launch(root_path='/dsw-619620/proxy/7860/')

if __name__ == "__main__":
    demo.queue().launch(share=True)


