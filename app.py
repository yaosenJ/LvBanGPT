import os
import gradio as gr
import requests
from gradio.components import HTML 
import uuid
from sparkai.core.messages import ChatMessage, AIMessageChunk
from dwspark.config import Config
from dwspark.models import ChatModel, ImageUnderstanding, Text2Audio, Audio2Text, EmbeddingModel
from PIL import Image
import io
import base64
import random
from langchain.vectorstores.chroma import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders.pdf import PyMuPDFLoader
from langchain_community.retrievers import BM25Retriever
from sklearn.metrics.pairwise import cosine_similarity 
import pickle
import re
import time
import numpy as np
from text2audio.infer import audio2lip
# æ—¥å¿—
from loguru import logger
# åŠ è½½è®¯é£çš„apié…ç½®
SPARKAI_APP_ID = os.environ.get("SPARKAI_APP_ID")
SPARKAI_API_SECRET = os.environ.get("SPARKAI_API_SECRET")
SPARKAI_API_KEY = os.environ.get("SPARKAI_API_KEY")
config = Config(SPARKAI_APP_ID, SPARKAI_API_KEY, SPARKAI_API_SECRET)

# åˆå§‹åŒ–æ¨¡å‹
iu = ImageUnderstanding(config)
t2a = Text2Audio(config)

# ä¸´æ—¶å­˜å‚¨ç›®å½•
TEMP_IMAGE_DIR = "/tmp/sparkai_images/"
#AUDIO_TEMP_DIR = "/tmp/sparkai_audios/"

style_options = ["æœ‹å‹åœˆ", "å°çº¢ä¹¦", "å¾®åš", "æŠ–éŸ³"]

# ä¿å­˜å›¾ç‰‡å¹¶è·å–ä¸´æ—¶è·¯å¾„
def save_and_get_temp_url(image):
    if not os.path.exists(TEMP_IMAGE_DIR):
        os.makedirs(TEMP_IMAGE_DIR)
    unique_filename = str(uuid.uuid4()) + ".png"
    temp_filepath = os.path.join(TEMP_IMAGE_DIR, unique_filename)
    image.save(temp_filepath)
    return temp_filepath

# ç”Ÿæˆæ–‡æœ¬
def generate_text_from_image(image, style):
    temp_image_path = save_and_get_temp_url(image)
    prompt = "è¯·ç†è§£è¿™å¼ å›¾ç‰‡"
    image_description = iu.understanding(prompt, temp_image_path)
    question = f"æ ¹æ®å›¾ç‰‡æè¿°ï¼š{image_description}, ç”¨{style}é£æ ¼ç”Ÿæˆä¸€æ®µæ–‡å­—ã€‚"
    stream_model = ChatModel(config, stream=False)
    generated_text = stream_model.generate([ChatMessage(role="user", content=question)])
    return generated_text

# æ–‡æ¡ˆåˆ°è¯­éŸ³
def text_to_audio(text_input):
    try:
        audio_path = "./demo.mp3"
        t2a.gen_audio(text_input, audio_path)
        return audio_path
    except Exception as e:
        print(f"Error generating audio: {e}")

# ç¬¬ä¸€é˜¶æ®µï¼šç”¨æˆ·ä¸Šä¼ å›¾ç‰‡å¹¶é€‰æ‹©é£æ ¼åï¼Œç‚¹å‡»ç”Ÿæˆæ–‡æ¡ˆ
def on_generate_click(image, style):
    generated_text = generate_text_from_image(image, style)
    return generated_text

# ç¬¬äºŒé˜¶æ®µï¼šç‚¹å‡»â€œå°†æ–‡æ¡ˆè½¬ä¸ºè¯­éŸ³â€æŒ‰é’®ï¼Œç”Ÿæˆå¹¶æ’­æ”¾è¯­éŸ³
def on_convert_click(text_output):
    return text_to_audio(text_output)

# ç¬¬ä¸‰é˜¶æ®µï¼šç‚¹å‡»â€œå°†æ–‡æ¡ˆè½¬ä¸ºæ•°å­—äººè§†é¢‘â€æŒ‰é’®ï¼Œç”Ÿæˆå¹¶æ’­æ”¾è¯­éŸ³
def on_lip_click(text_output,video_path='./shuziren.mp4'):
    video_output = audio2lip(text_output,video_path)
    return video_output
    
rerank_path = './model/rerank_model'
rerank_model_name = 'BAAI/bge-reranker-large'
def extract_cities_from_text(text):
    # ä»æ–‡æœ¬ä¸­æå–åŸå¸‚åç§°ï¼Œå‡è®¾ä½¿ç”¨jiebaè¿›è¡Œåˆ†è¯å’Œæå–åœ°å
    import jieba.posseg as pseg
    words = pseg.cut(text)
    cities = [word for word, flag in words if flag == "ns"]
    return cities

def find_pdfs_with_city(cities, pdf_directory):
    matched_pdfs = {}
    for city in cities:
        matched_pdfs[city] = []
        for root, _, files in os.walk(pdf_directory):
            for file in files:
                if file.endswith(".pdf") and city in file:
                    matched_pdfs[city].append(os.path.join(root, file))
    return matched_pdfs

def get_embedding_pdf(text, pdf_directory):
    # ä»æ–‡æœ¬ä¸­æå–åŸå¸‚åç§°
    cities = extract_cities_from_text(text)
    # æ ¹æ®åŸå¸‚åç§°åŒ¹é…PDFæ–‡ä»¶
    city_to_pdfs = find_pdfs_with_city(cities, pdf_directory)
    return city_to_pdfs


# def load_rerank_model(model_name=rerank_model_name):
#     """
#     åŠ è½½é‡æ’åæ¨¡å‹ã€‚
    
#     å‚æ•°:
#     - model_name (str): æ¨¡å‹çš„åç§°ã€‚é»˜è®¤ä¸º 'BAAI/bge-reranker-large'ã€‚
    
#     è¿”å›:
#     - FlagReranker å®ä¾‹ã€‚
    
#     å¼‚å¸¸:
#     - ValueError: å¦‚æœæ¨¡å‹åç§°ä¸åœ¨æ‰¹å‡†çš„æ¨¡å‹åˆ—è¡¨ä¸­ã€‚
#     - Exception: å¦‚æœæ¨¡å‹åŠ è½½è¿‡ç¨‹ä¸­å‘ç”Ÿä»»ä½•å…¶ä»–é”™è¯¯ã€‚
#     """ 
#     if not os.path.exists(rerank_path):
#         os.makedirs(rerank_path, exist_ok=True)
#     rerank_model_path = os.path.join(rerank_path, model_name.split('/')[1] + '.pkl')
#     #print(rerank_model_path)
#     logger.info('Loading rerank model...')
#     if os.path.exists(rerank_model_path):
#         try:
#             with open(rerank_model_path , 'rb') as f:
#                 reranker_model = pickle.load(f)
#                 logger.info('Rerank model loaded.')
#                 return reranker_model
#         except Exception as e:
#             logger.error(f'Failed to load embedding model from {rerank_model_path}') 
#     else:
#         try:
#             os.system('apt install git')
#             os.system('apt install git-lfs')
#             os.system(f'git clone https://code.openxlab.org.cn/answer-qzd/bge_rerank.git {rerank_path}')
#             os.system(f'cd {rerank_path} && git lfs pull')
            
#             with open(rerank_model_path , 'rb') as f:
#                 reranker_model = pickle.load(f)
#                 logger.info('Rerank model loaded.')
#                 return reranker_model
                
#         except Exception as e:
#             logger.error(f'Failed to load rerank model: {e}')

# def rerank(reranker, query, contexts, select_num):
#         merge = [[query, context] for context in contexts]
#         scores = reranker.compute_score(merge)
#         sorted_indices = np.argsort(scores)[::-1]

#         return [contexts[i] for i in sorted_indices[:select_num]]

def embedding_make(text_input, pdf_directory):

    city_to_pdfs = get_embedding_pdf(text_input, pdf_directory)
    city_list = []
    for city, pdfs in city_to_pdfs.items():
        print(f"City: {city}")
        for pdf in pdfs:
            city_list.append(pdf)
    
    if len(city_list) != 0:
        # all_pdf_pages = []
        all_text = ''
        for city in city_list:
            from pdf_read import FileOperation
            file_opr = FileOperation()
            try:
                text, error = file_opr.read(city)
            except:
                continue
            all_text += text
            
        pattern = re.compile(r'[^\u4e00-\u9fff](\n)[^\u4e00-\u9fff]', re.DOTALL)
        all_text = re.sub(pattern, lambda match: match.group(0).replace('\n', ''), all_text)

        text_spliter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=300) 
        docs = text_spliter.create_documents([all_text])
        splits = text_spliter.split_documents(docs)
        question=text_input
        
        retriever = BM25Retriever.from_documents(splits)
        #retriever.k = 20
        retriever.k = 10
        bm25_result = retriever.invoke(question)


        em = EmbeddingModel(config)
        question_vector = em.get_embedding(question)
        pdf_vector_list = []
        
        start_time = time.perf_counter()

        em = EmbeddingModel(config)  
        for i in range(len(bm25_result)):
            x = em.get_embedding(bm25_result[i].page_content) 
            pdf_vector_list.append(x)
            time.sleep(0.65)

        query_embedding = np.array(question_vector)
        query_embedding = query_embedding.reshape(1, -1)

        similarities = cosine_similarity(query_embedding, pdf_vector_list)

        top_k = 10
        top_k_indices = np.argsort(similarities[0])[-top_k:][::-1]

        emb_list = []
        for idx in top_k_indices:
            all_page = splits[idx].page_content
            emb_list.append(all_page)
        print(len(emb_list))

        #reranker_model = load_rerank_model()

        #documents = rerank(reranker_model, question, emb_list, 3)
        #logger.info("After rerank...")
        # reranked = []
        # for doc in documents:
        #     reranked.append(doc)
        # print(len(reranked))
        # reranked = ''.join(reranked)

        model_input = f'ä½ æ˜¯ä¸€ä¸ªæ—…æ¸¸æ”»ç•¥å°åŠ©æ‰‹ï¼Œä½ çš„ä»»åŠ¡æ˜¯ï¼Œæ ¹æ®æ”¶é›†åˆ°çš„ä¿¡æ¯ï¼š\n{emb_list}.\næ¥ç²¾å‡†å›ç­”ç”¨æˆ·æ‰€æå‡ºçš„é—®é¢˜ï¼š{question}ã€‚'
        #print(reranked)

        model = ChatModel(config, stream=False)
        output = model.generate([ChatMessage(role="user", content=model_input)])

        return output
    else:
        return "è¯·åœ¨è¾“å…¥ä¸­æåŠæƒ³è¦å’¨è¯¢çš„åŸå¸‚ï¼"

def process_question(history, use_knowledge_base, question, pdf_directory='./dataset'):
    if use_knowledge_base=='æ˜¯':
        response = embedding_make(question, pdf_directory)
    else:
        model = ChatModel(config, stream=False)
        response = model.generate([ChatMessage(role="user", content=question)])
    
    history.append((question, response))
    return "", history

def clear_history(history):
    history.clear()
    return history

# è·å–åŸå¸‚ä¿¡æ¯ 
def get_location_data(location,api_key):  
    """  
    å‘ QWeather API å‘é€ GET è¯·æ±‚ä»¥è·å–å¤©æ°”æ•°æ®ã€‚  
  
    :param location: åœ°ç‚¹åç§°æˆ–ç»çº¬åº¦ï¼ˆä¾‹å¦‚ï¼š"beijing" æˆ– "116.405285,39.904989"ï¼‰  
    :param api_key: ä½ çš„ QWeather API å¯†é’¥  
    :return: å“åº”çš„ JSON æ•°æ®  
    """  
    # æ„å»ºè¯·æ±‚ URL  
    url = f"https://geoapi.qweather.com/v2/city/lookup?location={location}&key={api_key}"  
  
    # å‘é€ GET è¯·æ±‚  
    response = requests.get(url)  
  
    # æ£€æŸ¥å“åº”çŠ¶æ€ç   
    if response.status_code == 200:  
        # è¿”å› JSON æ•°æ®  
        return response.json()
    else:  
        # å¤„ç†é”™è¯¯æƒ…å†µ  
        print(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")  
        print(response.text)  
        return None
    
# è·å–å¤©æ°”  
def get_weather_forecast(location_id,api_key):  
    """  
    å‘QWeather APIå‘é€è¯·æ±‚ä»¥è·å–æœªæ¥å‡ å¤©çš„å¤©æ°”é¢„æŠ¥ã€‚  
  
    å‚æ•°:  
    - location: åœ°ç‚¹IDæˆ–ç»çº¬åº¦  
    - api_key: ä½ çš„QWeather APIå¯†é’¥  
    - duration: é¢„æŠ¥çš„æ—¶é•¿ï¼Œ'3d' æˆ– '7d'  
  
    è¿”å›:  
    - å“åº”çš„JSONå†…å®¹  
    """
    
    # æ„å»ºè¯·æ±‚çš„URL  
    url = f"https://devapi.qweather.com/v7/weather/3d?location={location_id}&key={api_key}"  
  
    # å‘é€GETè¯·æ±‚  
    response = requests.get(url)  
  
    # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ  
    if response.status_code == 200:  
        # è¿”å›å“åº”çš„JSONå†…å®¹  
        return response.json()  
    else:  
        # å¦‚æœè¯·æ±‚ä¸æˆåŠŸï¼Œæ‰“å°é”™è¯¯ä¿¡æ¯  
        print(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}ï¼Œé”™è¯¯ä¿¡æ¯ï¼š{response.text}")  
        return None  

# æ—…è¡Œè§„åˆ’å¸ˆåŠŸèƒ½
prompt = 'ä½ ç°åœ¨æ˜¯ä¸€ä½ä¸“ä¸šçš„æ—…è¡Œè§„åˆ’å¸ˆï¼Œä½ çš„è´£ä»»æ˜¯æ ¹æ®æ—…è¡Œå‡ºå‘åœ°ï¼Œç›®çš„åœ°ã€å¤©æ•°ã€è¡Œç¨‹é£æ ¼ï¼ˆç´§å‡‘ã€é€‚ä¸­ã€ä¼‘é—²ï¼‰ï¼Œå¸®åŠ©æˆ‘è§„åˆ’æ—…æ¸¸è¡Œç¨‹å¹¶ç”Ÿæˆæ—…è¡Œè®¡åˆ’è¡¨ã€‚è¯·ä½ ä»¥è¡¨æ ¼çš„æ–¹å¼å‘ˆç°ç»“æœã€‚ æ—…è¡Œè®¡åˆ’è¡¨çš„è¡¨å¤´è¯·åŒ…å«æ—¥æœŸã€åœ°ç‚¹ã€è¡Œç¨‹è®¡åˆ’ã€äº¤é€šæ–¹å¼ã€å¤‡æ³¨ã€‚æ‰€æœ‰è¡¨å¤´éƒ½ä¸ºå¿…å¡«é¡¹ï¼Œè¯·åŠ æ·±æ€è€ƒè¿‡ç¨‹ï¼Œä¸¥æ ¼éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š 1. æ—¥æœŸè¯·ä»¥DayNä¸ºæ ¼å¼å¦‚Day1ã€‚ 2. åœ°ç‚¹éœ€è¦å‘ˆç°å½“å¤©æ‰€åœ¨åŸå¸‚ï¼Œè¯·æ ¹æ®æ—¥æœŸã€è€ƒè™‘åœ°ç‚¹çš„åœ°ç†ä½ç½®è¿œè¿‘ï¼Œä¸¥æ ¼ä¸”åˆç†åˆ¶å®šåœ°ç‚¹ã€‚ 3. è¡Œç¨‹è®¡åˆ’éœ€åŒ…å«ä½ç½®ã€æ—¶é—´ã€æ´»åŠ¨ï¼Œå…¶ä¸­ä½ç½®éœ€è¦æ ¹æ®åœ°ç†ä½ç½®çš„è¿œè¿‘è¿›è¡Œæ’åºï¼Œä½ç½®çš„æ•°é‡å¯ä»¥æ ¹æ®è¡Œç¨‹é£æ ¼çµæ´»è°ƒæ•´ï¼Œå¦‚ä¼‘é—²åˆ™ä½ç½®æ•°é‡è¾ƒå°‘ã€ç´§å‡‘åˆ™ä½ç½®æ•°é‡è¾ƒå¤šï¼Œæ—¶é—´éœ€è¦æŒ‰ç…§ä¸Šåˆã€ä¸­åˆã€æ™šä¸Šåˆ¶å®šå¹¶ç»™å‡ºæ¯ä¸€ä¸ªä½ç½®æ‰€åœç•™çš„æ—¶é—´å¦‚ä¸Šåˆ10ç‚¹-ä¸­åˆ12ç‚¹ï¼Œæ´»åŠ¨éœ€è¦å‡†ç¡®æè¿°åœ¨ä½ç½®å‘ç”Ÿçš„å¯¹åº”æ´»åŠ¨å¦‚å‚è§‚xxxã€æ¸¸ç©xxxã€åƒé¥­ç­‰ï¼Œéœ€æ ¹æ®ä½ç½®åœç•™æ—¶é—´åˆç†å®‰æ’æ´»åŠ¨ç±»å‹ã€‚ 4. äº¤é€šæ–¹å¼éœ€æ ¹æ®åœ°ç‚¹ã€è¡Œç¨‹è®¡åˆ’ä¸­çš„æ¯ä¸ªä½ç½®çš„åœ°ç†è·ç¦»åˆç†é€‰æ‹©æ­¥è¡Œã€åœ°é“ã€é£æœºç­‰ä¸åŒçš„äº¤é€šæ–¹å¼ã€‚ 5. å¤‡æ³¨ä¸­éœ€è¦åŒ…æ‹¬å¯¹åº”è¡Œç¨‹è®¡åˆ’éœ€è¦è€ƒè™‘åˆ°çš„æ³¨æ„äº‹é¡¹ï¼Œä¿æŒå¤šæ ·æ€§ã€‚ ç°åœ¨è¯·ä½ ä¸¥æ ¼éµå®ˆä»¥ä¸Šè§„åˆ™ï¼Œæ ¹æ®æˆ‘çš„æ—…è¡Œç›®çš„åœ°ã€å¤©æ•°ã€è¡Œç¨‹é£æ ¼ï¼ˆç´§å‡‘ã€é€‚ä¸­ã€ä¼‘é—²ï¼‰ï¼Œå†ä»¥è¡¨æ ¼çš„æ–¹å¼ç”Ÿæˆåˆç†çš„æ—…è¡Œè®¡åˆ’è¡¨ï¼Œæä¾›è¡¨æ ¼åè¯·å†è¯¢é—®æˆ‘è¡Œç¨‹é£æ ¼ã€åå¥½ã€ç‰¹æ®Šè¦æ±‚ç­‰ï¼Œå¹¶æ ¹æ®æ­¤ä¿¡æ¯å®Œå–„å’Œä¼˜åŒ–æ—…è¡Œè®¡åˆ’è¡¨å†æ¬¡æä¾›ï¼Œç›´åˆ°æˆ‘æ»¡æ„ã€‚è®°ä½ä½ è¦æ ¹æ®æˆ‘æä¾›çš„æ—…è¡Œç›®çš„åœ°ã€å¤©æ•°ç­‰ä¿¡æ¯ä»¥è¡¨æ ¼å½¢å¼ç”Ÿæˆæ—…è¡Œè®¡åˆ’è¡¨ï¼Œæœ€ç»ˆç­”æ¡ˆä¸€å®šæ˜¯è¡¨æ ¼å½¢å¼ã€‚æ—…æ¸¸å‡ºå‘åœ°ï¼š{}ï¼Œæ—…æ¸¸ç›®çš„åœ°ï¼š{} ï¼Œå¤©æ•°ï¼š{} ï¼Œè¡Œç¨‹é£æ ¼ï¼š{}'

def chat(chat_destination, chat_history, chat_departure, chat_days, chat_style):
    stream_model = ChatModel(config, stream=True)
    final_query = prompt.format(chat_departure, chat_destination, chat_days, chat_style)
    prompts = [ChatMessage(role='user', content=final_query)]
    # å°†é—®é¢˜è®¾ä¸ºå†å²å¯¹è¯
    chat_history.append((chat_destination, ''))
    # å¯¹è¯åŒæ—¶æµå¼è¿”å›
    for chunk_text in stream_model.generate_stream(prompts):
        # æ€»ç»“ç­”æ¡ˆ
        answer = chat_history[-1][1] + chunk_text
        # æ›¿æ¢æœ€æ–°çš„å¯¹è¯å†…å®¹
        chat_history[-1] = (chat_destination, answer)
        # è¿”å›
        yield '', chat_history

# Gradioæ¥å£å®šä¹‰
with gr.Blocks() as demo:
    html_code = f"""
            <p align="center">
               <img src="./logo.png" alt="Logo" width="20%" style="border-radius: 5px;">
            </p>
            <h1 style="text-align: center;">ğŸ˜€ å˜¿ï¼Œæ—…æ¸¸çˆ±å¥½è€…ä»¬ï¼ å¿«æ¥è®¤è¯†ä½ çš„å…¨æ–°æ—…è¡Œä¼™ä¼´â€”â€”â€œLvBanæ£è¡Œâ€æ—…æ¸¸åŠ©æ‰‹ï¼</h1>
            <h2 style="text-align: center;">å®ƒåŸºäºæ˜Ÿç«å¤§æ¨¡å‹ä¸­çš„æ–‡ç”Ÿæ–‡,å›¾ç”Ÿæ–‡ä»¥åŠæ–‡ç”Ÿè¯­éŸ³æŠ€æœ¯ï¼Œæ—¨åœ¨ä¸º##å¸Œæœ›ä½“éªŒæ—…è¡Œä¹è¶£å¹¶è§„åˆ’ä¸ªæ€§åŒ–å’Œéš¾å¿˜æ—…ç¨‹çš„ä¸ªäººæä¾›åˆ›æ–°è§£å†³æ–¹æ¡ˆ##ã€‚é¦–å…ˆï¼Œåªéœ€æä¾›æ‚¨çš„æ—…è¡Œå‡ºå‘åœ°ã€ç›®çš„åœ°ã€å¤©æ•°ä»¥åŠæ‚¨åå¥½çš„è¡Œç¨‹é£æ ¼ï¼ˆå¦‚ç´§å‡‘ã€é€‚ä¸­æˆ–ä¼‘é—²ï¼‰ï¼Œæˆ‘ä»¬çš„åŠ©æ‰‹å°±èƒ½ä¸ºæ‚¨ç²¾å¿ƒè§„åˆ’è¡Œç¨‹ï¼Œå¹¶ç”Ÿæˆè¯¦å°½çš„æ—…è¡Œè®¡åˆ’è¡¨ï¼ˆe.g: æ¯å¤©çš„è¡Œç¨‹è®¡åˆ’ï¼Œäº¤é€šæ–¹å¼ï¼Œéœ€è¦æ³¨æ„çš„ç‚¹ï¼‰ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨æ˜Ÿç«çš„å‘é‡æ¨¡å‹ï¼Œä½¿ç”¨RAGæŠ€æœ¯ï¼Œä»æ•°æ®åº“ä¸­æ£€ç´¢å‡ºä¸ç”¨æˆ·è¯¢é—®ç›¸å…³çš„å†…å®¹ï¼Œè®©æ¨¡å‹ç”Ÿæˆæ›´åŠ å¯é ï¼Œå‡†ç¡®ã€‚æ­¤å¤–ï¼Œæ‚¨è¿˜å¯ä»¥éšæ‰‹æ‹æ‘„æ—…é€”ä¸­çš„ç…§ç‰‡ï¼Œå¹¶é€šè¿‡æˆ‘ä»¬çš„åº”ç”¨ä¸Šä¼ ã€‚åº”ç”¨å°†è‡ªåŠ¨ä¸ºæ‚¨ç”Ÿæˆé€‚åˆä¸åŒç¤¾äº¤åª’ä½“å¹³å°ï¼ˆå¦‚æœ‹å‹åœˆã€å°çº¢ä¹¦ã€æŠ–éŸ³ã€å¾®åšï¼‰çš„æ–‡æ¡ˆé£æ ¼ï¼Œè®©æ‚¨èƒ½å¤Ÿè½»æ¾åˆ†äº«æ—…é€”ä¸­çš„ç‚¹æ»´ï¼Œä¸æœ‹å‹ä»¬ä¸€èµ·äº«å—æ—…æ¸¸çš„ä¹è¶£ã€‚</h2>
            """
    gr.Markdown(html_code)
    with gr.Tab("æ—…è¡Œè§„åˆ’å¸ˆ"):
        warning_html_code = """
                <div class="hint" style="text-align: center;background-color: rgba(255, 255, 0, 0.15); padding: 10px; margin: 10px; border-radius: 5px; border: 1px solid #ffcc00;">
                    <p>ğŸ± æ¬¢è¿æ¥åˆ°LvBanæ—…æ¸¸åŠ©æ‰‹ï¼Œæ ¹æ®æ‚¨æä¾›çš„æ—…è¡Œå‡ºå‘åœ°ï¼Œç›®çš„åœ°ã€å¤©æ•°ã€è¡Œç¨‹é£æ ¼ï¼ˆç´§å‡‘ã€é€‚ä¸­ã€ä¼‘é—²ï¼‰ï¼Œå¸®åŠ©æ‚¨è§„åˆ’æ—…æ¸¸è¡Œç¨‹å¹¶ç”Ÿæˆæ—…è¡Œè®¡åˆ’è¡¨</p>
                    <p>ç›¸å…³åœ°å€: <a href="https://challenge.xfyun.cn/h5/xinghuo?ch=dwm618">æ¯”èµ›åœ°å€</a>ã€<a href="https://github.com/yaosenJ/LvBanGPT">é¡¹ç›®åœ°å€</a></p>
                </div>
                """
        gr.HTML(warning_html_code)
        # è¾“å…¥æ¡†
        chat_departure = gr.Textbox(label="è¾“å…¥æ—…æ¸¸å‡ºå‘åœ°", placeholder="è¯·ä½ è¾“å…¥å‡ºå‘åœ°")
        chat_destination = gr.Textbox(label="è¾“å…¥æ—…æ¸¸ç›®çš„åœ°", placeholder="è¯·ä½ è¾“å…¥æƒ³å»çš„åœ°æ–¹")
        
        chat_days = gr.Radio(choices=['1å¤©', '2å¤©', '3å¤©', '4å¤©', '5å¤©', '6å¤©', '7å¤©', '8å¤©', '9å¤©', '10å¤©'], value='3å¤©', label='æ—…æ¸¸å¤©æ•°')
        chat_style = gr.Radio(choices=['ç´§å‡‘', 'é€‚ä¸­', 'ä¼‘é—²'], value='é€‚ä¸­', label='è¡Œç¨‹é£æ ¼')
        
        # èŠå¤©å¯¹è¯æ¡†
        chatbot = gr.Chatbot([], elem_id="chat-box", label="èŠå¤©å†å²")
        # æŒ‰é’®
        llm_submit_tab = gr.Button("å‘é€", visible=True)
        # é—®é¢˜æ ·ä¾‹
        gr.Examples(["åˆè‚¥", "éƒ‘å·", "è¥¿å®‰", "åŒ—äº¬", "å¹¿å·", "å¤§è¿"], chat_departure)
        gr.Examples(["åŒ—äº¬", "å—äº¬", "å¤§ç†", "ä¸Šæµ·", "ä¸œäº¬", "å·´é»"], chat_destination)
        # æŒ‰é’®å‡ºå‘é€»è¾‘
        llm_submit_tab.click(fn=chat, inputs=[chat_destination, chatbot, chat_departure, chat_days, chat_style], outputs=[chat_destination, chatbot])
        
    with gr.Tab("æ—…è¡Œæ”»ç•¥å°å«å£«"):
        warning_html_code = """
            <div class="hint" style="text-align: center;background-color: rgba(255, 255, 0, 0.15); padding: 10px; margin: 10px; border-radius: 5px; border: 1px solid #ffcc00;">
                <p>ğŸ± æ¬¢è¿æ¥åˆ°LvBanæ—…æ¸¸åŠ©æ‰‹ï¼Œæˆ‘å¯ä»¥æä¾›æ™¯ç‚¹æ¨èã€æ´»åŠ¨å®‰æ’ã€é¤é¥®ã€ä½å®¿ã€è´­ç‰©ã€è¡Œç¨‹æ¨èã€å®ç”¨å°è´´å£«ç­‰å®ç”¨å…¨æ–¹ä½ä¿¡æ¯</p>
                <p>ç›®å‰çŸ¥è¯†åº“åŒ…å«å…¨å›½å„åœ°åŒºã€åŸå¸‚æ—…æ¸¸æ”»ç•¥ä¿¡æ¯ã€‚å¦‚ï¼šé‡åº†ã€é¦™æ¸¯ã€åŒ—äº¬ã€é»„å±±ã€æ–°ç–†ã€å¦é—¨ã€å¤§ç†ç­‰å‡ ç™¾ä¸ªæ™¯ç‚¹</p>
                <p>ç›¸å…³åœ°å€: <a href="https://challenge.xfyun.cn/h5/xinghuo?ch=dwm618">æ¯”èµ›åœ°å€</a>ã€<a href="https://github.com/yaosenJ/LvBanGPT">é¡¹ç›®åœ°å€</a></p>
            </div>
            """
        gr.HTML(warning_html_code)
        chatbot = gr.Chatbot(label="èŠå¤©è®°å½•")
        msg = gr.Textbox(lines=2,placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼ˆæ—…æ¸¸æ™¯ç‚¹ã€æ´»åŠ¨ã€é¤é¥®ã€ä½å®¿ã€è´­ç‰©ã€æ¨èè¡Œç¨‹ã€å°è´´å£«ç­‰å®ç”¨ä¿¡æ¯ï¼‰",label="æä¾›æ™¯ç‚¹æ¨èã€æ´»åŠ¨å®‰æ’ã€é¤é¥®ã€ä½å®¿ã€è´­ç‰©ã€è¡Œç¨‹æ¨èã€å®ç”¨å°è´´å£«ç­‰å®ç”¨ä¿¡æ¯")
        whether_rag = gr.Radio(choices=['æ˜¯','å¦'], value='å¦', label='æ˜¯å¦å¯ç”¨RAG')
        submit_button = gr.Button("å‘é€")
        clear_button = gr.Button("æ¸…é™¤å¯¹è¯")
        # é—®é¢˜æ ·ä¾‹
        gr.Examples(["æˆ‘æƒ³å»é¦™æ¸¯ç©ï¼Œä½ æœ‰ä»€ä¹ˆæ¨èçš„å—ï¼Ÿ","æˆ‘è®¡åˆ’æš‘å‡å¸¦å®¶äººå»äº‘å—æ—…æ¸¸ï¼Œè¯·é—®æœ‰å“ªäº›å¿…æ¸¸çš„è‡ªç„¶é£å…‰å’Œæ°‘æ—æ–‡åŒ–æ™¯ç‚¹ï¼Ÿ","ä¸‹ä¸ªæœˆæˆ‘å°†åœ¨è¥¿å®‰ï¼Œæƒ³äº†è§£ç§¦å§‹çš‡å…µé©¬ä¿‘å¼€é€šæ—¶é—´ä»¥åŠäº¤é€šä¿¡æ¯","ç¬¬ä¸€æ¬¡å»è¥¿è—æ—…æ¸¸ï¼Œéœ€è¦æ³¨æ„å“ªäº›é«˜åŸååº”çš„é¢„é˜²æªæ–½ï¼Ÿ","å»ä¸‰äºšåº¦å‡ï¼Œæƒ³è¦ä½æµ·æ™¯é…’åº—ï¼Œæ€§ä»·æ¯”é«˜çš„é€‰æ‹©æœ‰å“ªäº›ï¼Ÿ","å»æ¾³é—¨æ—…æ¸¸çš„æœ€ä½³æ—¶é—´æ˜¯ä»€ä¹ˆæ—¶å€™ï¼Ÿ","è®¡åˆ’ä¸€æ¬¡äº”å¤©å››å¤œçš„è¥¿å®‰æ·±åº¦æ¸¸ï¼Œæ€æ ·å®‰æ’è¡Œç¨‹æ¯”è¾ƒåˆç†ï¼Œèƒ½è¦†ç›–ä¸»è¦æ™¯ç‚¹ï¼Ÿ","åœ¨æ­å·ï¼Œå“ªäº›å®¶é¤é¦†å¯ä»¥æ¨èå»çš„ï¼Ÿ"], msg)
        def respond(message, chat_history, use_kb):
            return process_question(chat_history, use_kb, message)

        def clear_chat(chat_history):
            return clear_history(chat_history)

        submit_button.click(respond, [msg, chatbot, whether_rag], [msg, chatbot])
        clear_button.click(clear_chat, chatbot, chatbot)
        weather_input = gr.Textbox(label="è¯·è¾“å…¥åŸå¸‚åæŸ¥è¯¢å¤©æ°”", placeholder="ä¾‹å¦‚ï¼šåŒ—äº¬")
        weather_output = gr.HTML(value="", label="å¤©æ°”æŸ¥è¯¢ç»“æœ")
        query_button = gr.Button("æŸ¥è¯¢å¤©æ°”")
        Weather_APP_KEY = os.environ.get("Weather_APP_KEY")
        def weather_process(location):
                api_key = Weather_APP_KEY  # æ›¿æ¢æˆä½ çš„APIå¯†é’¥  
                location_data = get_location_data(location, api_key)
                # print(location_data)
                if not location_data:
                    return "æ— æ³•è·å–åŸå¸‚ä¿¡æ¯ï¼Œè¯·æ£€æŸ¥æ‚¨çš„è¾“å…¥ã€‚"
                location_id = location_data.get('location', [{}])[0].get('id')
                # print(location_id)
                if not location_id:
                    return "æ— æ³•ä»åŸå¸‚ä¿¡æ¯ä¸­è·å–IDã€‚"
                weather_data = get_weather_forecast(location_id, api_key)
                if not weather_data or weather_data.get('code') != '200':
                    return "æ— æ³•è·å–å¤©æ°”é¢„æŠ¥ï¼Œè¯·æ£€æŸ¥æ‚¨çš„è¾“å…¥å’ŒAPIå¯†é’¥ã€‚"
                # æ„å»ºHTMLè¡¨æ ¼æ¥å±•ç¤ºå¤©æ°”æ•°æ®
                html_content = "<table>"
                html_content += "<tr>"
                html_content += "<th>é¢„æŠ¥æ—¥æœŸ</th>"
                html_content += "<th>ç™½å¤©å¤©æ°”</th>"
                html_content += "<th>å¤œé—´å¤©æ°”</th>"
                html_content += "<th>æœ€é«˜æ¸©åº¦</th>"
                html_content += "<th>æœ€ä½æ¸©åº¦</th>"
                html_content += "<th>ç™½å¤©é£å‘</th>"
                html_content += "<th>ç™½å¤©é£åŠ›ç­‰çº§</th>"
                html_content += "<th>ç™½å¤©é£é€Ÿ</th>"
                html_content += "<th>å¤œé—´é£å‘</th>"
                html_content += "<th>å¤œé—´é£åŠ›ç­‰çº§</th>"
                html_content += "<th>å¤œé—´é£é€Ÿ</th>"
                html_content += "<th>æ€»é™æ°´é‡</th>"
                html_content += "<th>ç´«å¤–çº¿å¼ºåº¦</th>"
                html_content += "<th>ç›¸å¯¹æ¹¿åº¦</th>"
                html_content += "</tr>"

                for day in weather_data.get('daily', []):
                    html_content += f"<tr>"
                    html_content += f"<td>{day['fxDate']}</td>"
                    html_content += f"<td>{day['textDay']} ({day['iconDay']})</td>"
                    html_content += f"<td>{day['textNight']} ({day['iconNight']})</td>"
                    html_content += f"<td>{day['tempMax']}Â°C</td>"
                    html_content += f"<td>{day['tempMin']}Â°C</td>"
                    html_content += f"<td>{day.get('windDirDay', 'æœªçŸ¥')}</td>"
                    html_content += f"<td>{day.get('windScaleDay', 'æœªçŸ¥')}</td>"
                    html_content += f"<td>{day.get('windSpeedDay', 'æœªçŸ¥')} km/h</td>"
                    html_content += f"<td>{day.get('windDirNight', 'æœªçŸ¥')}</td>"
                    html_content += f"<td>{day.get('windScaleNight', 'æœªçŸ¥')}</td>"
                    html_content += f"<td>{day.get('windSpeedNight', 'æœªçŸ¥')} km/h</td>"
                    html_content += f"<td>{day.get('precip', 'æœªçŸ¥')} mm</td>"
                    html_content += f"<td>{day.get('uvIndex', 'æœªçŸ¥')}</td>"
                    html_content += f"<td>{day.get('humidity', 'æœªçŸ¥')}%</td>"
                    html_content += "</tr>"
                html_content += "</table>"  
  
                return HTML(html_content)  
        query_button.click(weather_process, [weather_input], [weather_output])
    

    with gr.Tab("æ—…è¡Œæ™ºèƒ½æ–‡æ¡ˆç”Ÿæˆ"):
        warning_html_code = """
                <div class="hint" style="text-align: center;background-color: rgba(255, 255, 0, 0.15); padding: 10px; margin: 10px; border-radius: 5px; border: 1px solid #ffcc00;">
                    <p>ğŸ± æ¬¢è¿æ¥åˆ°LvBanæ—…æ¸¸åŠ©æ‰‹ï¼Œæ ¹æ®ä½ éšæ‰‹æ‹çš„ç…§ç‰‡ï¼Œä¸Šä¼ åˆ°è¯¥åº”ç”¨ï¼Œè‡ªåŠ¨ç”Ÿæˆä½ æƒ³è¦çš„æ–‡æ¡ˆé£æ ¼æ¨¡å¼ï¼ˆæœ‹å‹åœˆã€å°çº¢ä¹¦ã€æŠ–éŸ³ã€å¾®åšï¼‰ï¼Œç„¶ååˆ†äº«ç»™å¤§å®¶ï¼Œä¸€èµ·äº«å—æ—…æ¸¸æ„‰å¿«ã€‚</p>
                    <p>ç›¸å…³åœ°å€: <a href="https://challenge.xfyun.cn/h5/xinghuo?ch=dwm618">æ¯”èµ›åœ°å€</a>ã€<a href="https://github.com/yaosenJ/LvBanGPT">é¡¹ç›®åœ°å€</a></p>
                </div>
                """
        gr.HTML(warning_html_code)
        with gr.Row():
            image_input = gr.Image(type="pil", label="ä¸Šä¼ å›¾åƒ")
            style_dropdown = gr.Dropdown(choices=style_options, label="é€‰æ‹©é£æ ¼æ¨¡å¼", value="æœ‹å‹åœˆ")
            audio_output = gr.Audio(label="éŸ³é¢‘æ’­æ”¾", interactive=False, visible=True)
            video_output = gr.Video(label="æ•°å­—äºº",visible=True)

        with gr.Column():
            generate_button = gr.Button("ç”Ÿæˆæ–‡æ¡ˆ", visible=True)
            generated_text = gr.Textbox(lines=8, label="ç”Ÿæˆçš„æ–‡æ¡ˆ", visible=True)
                     
        generate_button.click(on_generate_click, inputs=[image_input, style_dropdown], outputs=[generated_text])
        convert_button1 = gr.Button("å°†æ–‡æ¡ˆè½¬ä¸ºè¯­éŸ³", visible=True)
        convert_button1.click(on_convert_click, inputs=[generated_text], outputs=[audio_output])
        convert_button2 = gr.Button("å°†æ–‡æ¡ˆè½¬ä¸ºè§†é¢‘(è¯·è€å¿ƒç­‰å¾…)", visible=True)
        convert_button2.click(on_lip_click, inputs=[generated_text],outputs=[video_output])

if __name__ == "__main__":
    demo.queue().launch(share=True)


