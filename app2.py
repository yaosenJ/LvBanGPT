import os
import gradio as gr
import uuid
from sparkai.core.messages import ChatMessage,AIMessageChunk
from dwspark.config import Config
from dwspark.models import ChatModel, ImageUnderstanding, Text2Audio,Audio2Text,EmbeddingModel
from PIL import Image
import io
import base64
import random
from langchain.vectorstores.chroma import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders.pdf import PyMuPDFLoader
from sklearn.metrics.pairwise import cosine_similarity 
import gradio as gr
import pickle
import os
import re
import time
import numpy as np

from langchain_community.retrievers import BM25Retriever

# æ—¥å¿—
from loguru import logger
# åŠ è½½è®¯é£çš„apié…ç½®
SPARKAI_APP_ID = os.environ.get("SPARKAI_APP_ID")
SPARKAI_API_SECRET = os.environ.get("SPARKAI_API_SECRET")
SPARKAI_API_KEY = os.environ.get("SPARKAI_API_KEY")
config = Config(SPARKAI_APP_ID, SPARKAI_API_KEY, SPARKAI_API_SECRET)

# åˆå§‹åŒ–æ¨¡å‹
iu = ImageUnderstanding(config)
t2a = Text2Audio(config)

# ä¸´æ—¶å­˜å‚¨ç›®å½•
TEMP_IMAGE_DIR = "/tmp/sparkai_images/"
#AUDIO_TEMP_DIR = "/tmp/sparkai_audios/"

style_options = ["æœ‹å‹åœˆ", "å°çº¢ä¹¦", "å¾®åš", "æŠ–éŸ³"]

# ä¿å­˜å›¾ç‰‡å¹¶è·å–ä¸´æ—¶è·¯å¾„
def save_and_get_temp_url(image):
    if not os.path.exists(TEMP_IMAGE_DIR):
        os.makedirs(TEMP_IMAGE_DIR)
    unique_filename = str(uuid.uuid4()) + ".png"
    temp_filepath = os.path.join(TEMP_IMAGE_DIR, unique_filename)
    image.save(temp_filepath)
    return temp_filepath

# ç”Ÿæˆæ–‡æœ¬
def generate_text_from_image(image, style):
    temp_image_path = save_and_get_temp_url(image)
    prompt = "è¯·ç†è§£è¿™å¼ å›¾ç‰‡"
    image_description = iu.understanding(prompt, temp_image_path)
    question = f"æ ¹æ®å›¾ç‰‡æè¿°ï¼š{image_description}, ç”¨{style}é£æ ¼ç”Ÿæˆä¸€æ®µæ–‡å­—ã€‚"
    stream_model = ChatModel(config, stream=False)
    generated_text = stream_model.generate([ChatMessage(role="user", content=question)])
    return generated_text

# æ–‡æ¡ˆåˆ°è¯­éŸ³
def text_to_audio(text_input):
    try:
        audio_path = "./demo.mp3"
        t2a.gen_audio(text_input, audio_path)
        return audio_path
    except Exception as e:
        print(f"Error generating audio: {e}")
        return gr.Text.update(value="è¯­éŸ³ç”Ÿæˆå¤±è´¥ï¼Œè¯·é‡è¯•ã€‚")

# ç¬¬ä¸€é˜¶æ®µï¼šç”¨æˆ·ä¸Šä¼ å›¾ç‰‡å¹¶é€‰æ‹©é£æ ¼åï¼Œç‚¹å‡»ç”Ÿæˆæ–‡æ¡ˆ
def on_generate_click(image, style):
    generated_text = generate_text_from_image(image, style)
    return generated_text

# ç¬¬äºŒé˜¶æ®µï¼šç‚¹å‡»â€œå°†æ–‡æ¡ˆè½¬ä¸ºè¯­éŸ³â€æŒ‰é’®ï¼Œç”Ÿæˆå¹¶æ’­æ”¾è¯­éŸ³
def on_convert_click(text_output):
    return text_to_audio(text_output)

rerank_path = './model/rerank_model'
rerank_model_name = 'BAAI/bge-reranker-large'
def extract_cities_from_text(text):
    # ä»æ–‡æœ¬ä¸­æå–åŸå¸‚åç§°ï¼Œå‡è®¾ä½¿ç”¨jiebaè¿›è¡Œåˆ†è¯å’Œæå–åœ°å
    import jieba.posseg as pseg
    words = pseg.cut(text)
    cities = [word for word, flag in words if flag == "ns"]
    return cities

def find_pdfs_with_city(cities, pdf_directory):
    matched_pdfs = {}
    for city in cities:
        matched_pdfs[city] = []
        for root, _, files in os.walk(pdf_directory):
            for file in files:
                if file.endswith(".pdf") and city in file:
                    matched_pdfs[city].append(os.path.join(root, file))
    return matched_pdfs

def get_embedding_pdf(text, pdf_directory):
    # ä»æ–‡æœ¬ä¸­æå–åŸå¸‚åç§°
    cities = extract_cities_from_text(text)
    # æ ¹æ®åŸå¸‚åç§°åŒ¹é…PDFæ–‡ä»¶
    city_to_pdfs = find_pdfs_with_city(cities, pdf_directory)
    return city_to_pdfs


def load_rerank_model(model_name=rerank_model_name):
    """
    åŠ è½½é‡æ’åæ¨¡å‹ã€‚
    
    å‚æ•°:
    - model_name (str): æ¨¡å‹çš„åç§°ã€‚é»˜è®¤ä¸º 'BAAI/bge-reranker-large'ã€‚
    
    è¿”å›:
    - FlagReranker å®ä¾‹ã€‚
    
    å¼‚å¸¸:
    - ValueError: å¦‚æœæ¨¡å‹åç§°ä¸åœ¨æ‰¹å‡†çš„æ¨¡å‹åˆ—è¡¨ä¸­ã€‚
    - Exception: å¦‚æœæ¨¡å‹åŠ è½½è¿‡ç¨‹ä¸­å‘ç”Ÿä»»ä½•å…¶ä»–é”™è¯¯ã€‚
    
    """ 
    if not os.path.exists(rerank_path):
        os.makedirs(rerank_path, exist_ok=True)
    rerank_model_path = os.path.join(rerank_path, model_name.split('/')[1] + '.pkl')
    # print(rerank_model_path)
    logger.info('Loading rerank model...')
    if os.path.exists(rerank_model_path):
        try:
            with open(rerank_model_path , 'rb') as f:
                reranker_model = pickle.load(f)
                logger.info('Rerank model loaded.')
                return reranker_model
        except Exception as e:
            logger.error(f'Failed to load embedding model from {rerank_model_path}') 
    else:
        try:
            os.system('apt install git')
            os.system('apt install git-lfs')
            os.system(f'git clone https://code.openxlab.org.cn/answer-qzd/bge_rerank.git {rerank_path}')
            os.system(f'cd {rerank_path} && git lfs pull')
    
            with open(rerank_model_path , 'rb') as f:
                reranker_model = pickle.load(f)
                logger.info('Rerank model loaded.')
                return reranker_model
                
        except Exception as e:
            logger.error(f'Failed to load rerank model: {e}')

def rerank(reranker, query, contexts, select_num):
        merge = [[query, context] for context in contexts]
        scores = reranker.compute_score(merge)
        sorted_indices = np.argsort(scores)[::-1]

        return [contexts[i] for i in sorted_indices[:select_num]]

def embedding_make(text_input, pdf_directory):

    city_to_pdfs = get_embedding_pdf(text_input, pdf_directory)
    city_list = []
    for city, pdfs in city_to_pdfs.items():
        print(f"City: {city}")
        for pdf in pdfs:
            city_list.append(pdf)
    
    if len(city_list) != 0:
        # all_pdf_pages = []
        all_text = ''
        for city in city_list:
            from pdf_read import FileOperation
            file_opr = FileOperation()
            try:
                text, error = file_opr.read(city)
            except:
                continue
            all_text += text
            
        pattern = re.compile(r'[^\u4e00-\u9fff](\n)[^\u4e00-\u9fff]', re.DOTALL)
        all_text = re.sub(pattern, lambda match: match.group(0).replace('\n', ''), all_text)

        text_spliter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=300) 
        docs = text_spliter.create_documents([all_text])
        splits = text_spliter.split_documents(docs)
        question=text_input
        
        retriever = BM25Retriever.from_documents(splits)
        retriever.k = 20
        bm25_result = retriever.invoke(question)


        em = EmbeddingModel(config)
        question_vector = em.get_embedding(question)
        pdf_vector_list = []
        
        start_time = time.perf_counter()

        em = EmbeddingModel(config)  
        for i in range(len(bm25_result)):
            x = em.get_embedding(bm25_result[i].page_content) 
            pdf_vector_list.append(x)
            time.sleep(0.65)

        query_embedding = np.array(question_vector)
        query_embedding = query_embedding.reshape(1, -1)

        similarities = cosine_similarity(query_embedding, pdf_vector_list)

        top_k = 10
        top_k_indices = np.argsort(similarities[0])[-top_k:][::-1]

        emb_list = []
        for idx in top_k_indices:
            all_page = splits[idx].page_content
            emb_list.append(all_page)
        print(len(emb_list))

        reranker_model = load_rerank_model()

        documents = rerank(reranker_model, question, emb_list, 3)
        logger.info("After rerank...")
        reranked = []
        for doc in documents:
            reranked.append(doc)
        print(len(reranked))
        reranked = ''.join(reranked)

        model_input = f'ä½ æ˜¯ä¸€ä¸ªæ—…æ¸¸æ”»ç•¥å°åŠ©æ‰‹ï¼Œä½ çš„ä»»åŠ¡æ˜¯ï¼Œæ ¹æ®æ”¶é›†åˆ°çš„ä¿¡æ¯ï¼š\n{reranked}.\næ¥ç²¾å‡†å›ç­”ç”¨æˆ·æ‰€æå‡ºçš„é—®é¢˜ï¼š{question}ã€‚'
        #print(reranked)

        model = ChatModel(config, stream=False)
        output = model.generate([ChatMessage(role="user", content=model_input)])

        return output
    else:
        return "è¯·åœ¨è¾“å…¥ä¸­æåŠæƒ³è¦å’¨è¯¢çš„åŸå¸‚ï¼"

def process_question(history, use_knowledge_base, question, pdf_directory='./dataset'):
    if use_knowledge_base=='æ˜¯':
        response = embedding_make(question, pdf_directory)
    else:
        model = ChatModel(config, stream=False)
        response = model.generate([ChatMessage(role="user", content=question)])
    
    history.append((question, response))
    return "", history

def clear_history(history):
    history.clear()
    return history
 

# æ—…è¡Œè§„åˆ’å¸ˆåŠŸèƒ½
prompt = 'ä½ ç°åœ¨æ˜¯ä¸€ä½ä¸“ä¸šçš„æ—…è¡Œè§„åˆ’å¸ˆï¼Œä½ çš„è´£ä»»æ˜¯æ ¹æ®æ—…è¡Œå‡ºå‘åœ°ï¼Œç›®çš„åœ°ã€å¤©æ•°ã€è¡Œç¨‹é£æ ¼ï¼ˆç´§å‡‘ã€é€‚ä¸­ã€ä¼‘é—²ï¼‰ï¼Œå¸®åŠ©æˆ‘è§„åˆ’æ—…æ¸¸è¡Œç¨‹å¹¶ç”Ÿæˆæ—…è¡Œè®¡åˆ’è¡¨ã€‚è¯·ä½ ä»¥è¡¨æ ¼çš„æ–¹å¼å‘ˆç°ç»“æœã€‚ æ—…è¡Œè®¡åˆ’è¡¨çš„è¡¨å¤´è¯·åŒ…å«æ—¥æœŸã€åœ°ç‚¹ã€è¡Œç¨‹è®¡åˆ’ã€äº¤é€šæ–¹å¼ã€å¤‡æ³¨ã€‚æ‰€æœ‰è¡¨å¤´éƒ½ä¸ºå¿…å¡«é¡¹ï¼Œè¯·åŠ æ·±æ€è€ƒè¿‡ç¨‹ï¼Œä¸¥æ ¼éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š 1. æ—¥æœŸè¯·ä»¥DayNä¸ºæ ¼å¼å¦‚Day1ã€‚ 2. åœ°ç‚¹éœ€è¦å‘ˆç°å½“å¤©æ‰€åœ¨åŸå¸‚ï¼Œè¯·æ ¹æ®æ—¥æœŸã€è€ƒè™‘åœ°ç‚¹çš„åœ°ç†ä½ç½®è¿œè¿‘ï¼Œä¸¥æ ¼ä¸”åˆç†åˆ¶å®šåœ°ç‚¹ã€‚ 3. è¡Œç¨‹è®¡åˆ’éœ€åŒ…å«ä½ç½®ã€æ—¶é—´ã€æ´»åŠ¨ï¼Œå…¶ä¸­ä½ç½®éœ€è¦æ ¹æ®åœ°ç†ä½ç½®çš„è¿œè¿‘è¿›è¡Œæ’åºï¼Œä½ç½®çš„æ•°é‡å¯ä»¥æ ¹æ®è¡Œç¨‹é£æ ¼çµæ´»è°ƒæ•´ï¼Œå¦‚ä¼‘é—²åˆ™ä½ç½®æ•°é‡è¾ƒå°‘ã€ç´§å‡‘åˆ™ä½ç½®æ•°é‡è¾ƒå¤šï¼Œæ—¶é—´éœ€è¦æŒ‰ç…§ä¸Šåˆã€ä¸­åˆã€æ™šä¸Šåˆ¶å®šå¹¶ç»™å‡ºæ¯ä¸€ä¸ªä½ç½®æ‰€åœç•™çš„æ—¶é—´å¦‚ä¸Šåˆ10ç‚¹-ä¸­åˆ12ç‚¹ï¼Œæ´»åŠ¨éœ€è¦å‡†ç¡®æè¿°åœ¨ä½ç½®å‘ç”Ÿçš„å¯¹åº”æ´»åŠ¨å¦‚å‚è§‚xxxã€æ¸¸ç©xxxã€åƒé¥­ç­‰ï¼Œéœ€æ ¹æ®ä½ç½®åœç•™æ—¶é—´åˆç†å®‰æ’æ´»åŠ¨ç±»å‹ã€‚ 4. äº¤é€šæ–¹å¼éœ€æ ¹æ®åœ°ç‚¹ã€è¡Œç¨‹è®¡åˆ’ä¸­çš„æ¯ä¸ªä½ç½®çš„åœ°ç†è·ç¦»åˆç†é€‰æ‹©æ­¥è¡Œã€åœ°é“ã€é£æœºç­‰ä¸åŒçš„äº¤é€šæ–¹å¼ã€‚ 5. å¤‡æ³¨ä¸­éœ€è¦åŒ…æ‹¬å¯¹åº”è¡Œç¨‹è®¡åˆ’éœ€è¦è€ƒè™‘åˆ°çš„æ³¨æ„äº‹é¡¹ï¼Œä¿æŒå¤šæ ·æ€§ã€‚ ç°åœ¨è¯·ä½ ä¸¥æ ¼éµå®ˆä»¥ä¸Šè§„åˆ™ï¼Œæ ¹æ®æˆ‘çš„æ—…è¡Œç›®çš„åœ°ã€å¤©æ•°ã€è¡Œç¨‹é£æ ¼ï¼ˆç´§å‡‘ã€é€‚ä¸­ã€ä¼‘é—²ï¼‰ï¼Œå†ä»¥è¡¨æ ¼çš„æ–¹å¼ç”Ÿæˆåˆç†çš„æ—…è¡Œè®¡åˆ’è¡¨ï¼Œæä¾›è¡¨æ ¼åè¯·å†è¯¢é—®æˆ‘è¡Œç¨‹é£æ ¼ã€åå¥½ã€ç‰¹æ®Šè¦æ±‚ç­‰ï¼Œå¹¶æ ¹æ®æ­¤ä¿¡æ¯å®Œå–„å’Œä¼˜åŒ–æ—…è¡Œè®¡åˆ’è¡¨å†æ¬¡æä¾›ï¼Œç›´åˆ°æˆ‘æ»¡æ„ã€‚è®°ä½ä½ è¦æ ¹æ®æˆ‘æä¾›çš„æ—…è¡Œç›®çš„åœ°ã€å¤©æ•°ç­‰ä¿¡æ¯ä»¥è¡¨æ ¼å½¢å¼ç”Ÿæˆæ—…è¡Œè®¡åˆ’è¡¨ï¼Œæœ€ç»ˆç­”æ¡ˆä¸€å®šæ˜¯è¡¨æ ¼å½¢å¼ã€‚æ—…æ¸¸å‡ºå‘åœ°ï¼š{}ï¼Œæ—…æ¸¸ç›®çš„åœ°ï¼š{} ï¼Œå¤©æ•°ï¼š{} ï¼Œè¡Œç¨‹é£æ ¼ï¼š{}'

def chat(chat_destination, chat_history, chat_departure, chat_days, chat_style):
    stream_model = ChatModel(config, stream=True)
    final_query = prompt.format(chat_departure, chat_destination, chat_days, chat_style)
    prompts = [ChatMessage(role='user', content=final_query)]
    # å°†é—®é¢˜è®¾ä¸ºå†å²å¯¹è¯
    chat_history.append((chat_destination, ''))
    # å¯¹è¯åŒæ—¶æµå¼è¿”å›
    for chunk_text in stream_model.generate_stream(prompts):
        # æ€»ç»“ç­”æ¡ˆ
        answer = chat_history[-1][1] + chunk_text
        # æ›¿æ¢æœ€æ–°çš„å¯¹è¯å†…å®¹
        chat_history[-1] = (chat_destination, answer)
        # è¿”å›
        yield '', chat_history

# Gradioæ¥å£å®šä¹‰
with gr.Blocks() as demo:
    with gr.Tab("æ—…è¡Œè§„åˆ’å¸ˆ"):
        warning_html_code = """
                <div class="hint" style="text-align: center;background-color: rgba(255, 255, 0, 0.15); padding: 10px; margin: 10px; border-radius: 5px; border: 1px solid #ffcc00;">
                    <p>ğŸ± æ¬¢è¿æ¥åˆ°LvBanæ—…æ¸¸åŠ©æ‰‹ï¼Œæ ¹æ®æ‚¨æä¾›çš„æ—…è¡Œå‡ºå‘åœ°ï¼Œç›®çš„åœ°ã€å¤©æ•°ã€è¡Œç¨‹é£æ ¼ï¼ˆç´§å‡‘ã€é€‚ä¸­ã€ä¼‘é—²ï¼‰ï¼Œå¸®åŠ©æ‚¨è§„åˆ’æ—…æ¸¸è¡Œç¨‹å¹¶ç”Ÿæˆæ—…è¡Œè®¡åˆ’è¡¨</p>
                    <p>ç›¸å…³åœ°å€: <a href="https://challenge.xfyun.cn/h5/xinghuo?ch=dwm618">æ¯”èµ›åœ°å€</a>ã€<a href="https://github.com/yaosenJ/LvBanGPT">é¡¹ç›®åœ°å€</a></p>
                </div>
                """
        gr.HTML(warning_html_code)
        # è¾“å…¥æ¡†
        chat_departure = gr.Textbox(label="è¾“å…¥æ—…æ¸¸å‡ºå‘åœ°", placeholder="è¯·ä½ è¾“å…¥å‡ºå‘åœ°")
        chat_destination = gr.Textbox(label="è¾“å…¥æ—…æ¸¸ç›®çš„åœ°", placeholder="è¯·ä½ è¾“å…¥æƒ³å»çš„åœ°æ–¹")
        
        chat_days = gr.Radio(choices=['1å¤©', '2å¤©', '3å¤©', '4å¤©', '5å¤©', '6å¤©', '7å¤©', '8å¤©', '9å¤©', '10å¤©'], value='3å¤©', label='æ—…æ¸¸å¤©æ•°')
        chat_style = gr.Radio(choices=['ç´§å‡‘', 'é€‚ä¸­', 'ä¼‘é—²'], value='é€‚ä¸­', label='è¡Œç¨‹é£æ ¼')
        
        # èŠå¤©å¯¹è¯æ¡†
        chatbot = gr.Chatbot([], elem_id="chat-box", label="èŠå¤©å†å²")
        # æŒ‰é’®
        llm_submit_tab = gr.Button("å‘é€", visible=True)
        # é—®é¢˜æ ·ä¾‹
        gr.Examples(["åˆè‚¥", "éƒ‘å·", "è¥¿å®‰", "åŒ—äº¬", "å¹¿å·", "å¤§è¿"], chat_departure)
        gr.Examples(["åŒ—äº¬", "å—äº¬", "å¤§ç†", "ä¸Šæµ·", "ä¸œäº¬", "å·´é»"], chat_destination)
        # æŒ‰é’®å‡ºå‘é€»è¾‘
        llm_submit_tab.click(fn=chat, inputs=[chat_destination, chatbot, chat_departure, chat_days, chat_style], outputs=[chat_destination, chatbot])
        
    with gr.Tab("æ—…è¡Œæ”»ç•¥å°å«å£«"):
        warning_html_code = """
            <div class="hint" style="text-align: center;background-color: rgba(255, 255, 0, 0.15); padding: 10px; margin: 10px; border-radius: 5px; border: 1px solid #ffcc00;">
                <p>ğŸ± æ¬¢è¿æ¥åˆ°LvBanæ—…æ¸¸åŠ©æ‰‹ï¼Œæˆ‘å¯ä»¥æä¾›æ™¯ç‚¹æ¨èã€æ´»åŠ¨å®‰æ’ã€é¤é¥®ã€ä½å®¿ã€è´­ç‰©ã€è¡Œç¨‹æ¨èã€å®ç”¨å°è´´å£«ç­‰å®ç”¨å…¨æ–¹ä½ä¿¡æ¯</p>
                <p>ç›®å‰çŸ¥è¯†åº“åŒ…å«å…¨å›½å„åœ°åŒºã€åŸå¸‚æ—…æ¸¸æ”»ç•¥ä¿¡æ¯ã€‚å¦‚ï¼šå¤§è¿ã€é¦™æ¸¯ã€è´µé˜³ã€åŒ—äº¬ã€é»„å±±ã€æ–°ç–†ã€å¦é—¨ã€ä¸½æ±Ÿç­‰å‡ ç™¾ä¸ªæ™¯ç‚¹</p>
                <p>ç›¸å…³åœ°å€: <a href="https://challenge.xfyun.cn/h5/xinghuo?ch=dwm618">æ¯”èµ›åœ°å€</a>ã€<a href="https://github.com/yaosenJ/LvBanGPT">é¡¹ç›®åœ°å€</a></p>
            </div>
            """
        gr.HTML(warning_html_code)
        chatbot = gr.Chatbot(label="èŠå¤©è®°å½•")
        msg = gr.Textbox(lines=2,placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼ˆæ—…æ¸¸æ™¯ç‚¹ã€æ´»åŠ¨ã€é¤é¥®ã€ä½å®¿ã€è´­ç‰©ã€æ¨èè¡Œç¨‹ã€å°è´´å£«ç­‰å®ç”¨ä¿¡æ¯ï¼‰",label="æä¾›æ™¯ç‚¹æ¨èã€æ´»åŠ¨å®‰æ’ã€é¤é¥®ã€ä½å®¿ã€è´­ç‰©ã€è¡Œç¨‹æ¨èã€å®ç”¨å°è´´å£«ç­‰å®ç”¨ä¿¡æ¯")
        whether_rag = gr.Radio(choices=['æ˜¯','å¦'], value='å¦', label='æ˜¯å¦å¯ç”¨RAG')
        submit_button = gr.Button("å‘é€")
        clear_button = gr.Button("æ¸…é™¤å¯¹è¯")
        # é—®é¢˜æ ·ä¾‹
        gr.Examples(["æˆ‘æƒ³å»é¦™æ¸¯ç©ï¼Œä½ æœ‰ä»€ä¹ˆæ¨èçš„å—ï¼Ÿ","æˆ‘è®¡åˆ’æš‘å‡å¸¦å®¶äººå»äº‘å—æ—…æ¸¸ï¼Œè¯·é—®æœ‰å“ªäº›å¿…æ¸¸çš„è‡ªç„¶é£å…‰å’Œæ°‘æ—æ–‡åŒ–æ™¯ç‚¹ï¼Ÿ","ä¸‹ä¸ªæœˆæˆ‘å°†åœ¨è¥¿å®‰ï¼Œæƒ³äº†è§£ç§¦å§‹çš‡å…µé©¬ä¿‘å¼€é€šæ—¶é—´ä»¥åŠäº¤é€šä¿¡æ¯","ç¬¬ä¸€æ¬¡å»è¥¿è—æ—…æ¸¸ï¼Œéœ€è¦æ³¨æ„å“ªäº›é«˜åŸååº”çš„é¢„é˜²æªæ–½ï¼Ÿ","å»ä¸‰äºšåº¦å‡ï¼Œæƒ³è¦ä½æµ·æ™¯é…’åº—ï¼Œæ€§ä»·æ¯”é«˜çš„é€‰æ‹©æœ‰å“ªäº›ï¼Ÿ","å»æ¾³é—¨æ—…æ¸¸çš„æœ€ä½³æ—¶é—´æ˜¯ä»€ä¹ˆæ—¶å€™ï¼Ÿ","è®¡åˆ’ä¸€æ¬¡äº”å¤©å››å¤œçš„è¥¿å®‰æ·±åº¦æ¸¸ï¼Œæ€æ ·å®‰æ’è¡Œç¨‹æ¯”è¾ƒåˆç†ï¼Œèƒ½è¦†ç›–ä¸»è¦æ™¯ç‚¹ï¼Ÿ","åœ¨æ­å·ï¼Œå“ªäº›å®¶é¤é¦†å¯ä»¥æ¨èå»çš„ï¼Ÿ"], msg)
        def respond(message, chat_history, use_kb):
            return process_question(chat_history, use_kb, message)

        def clear_chat(chat_history):
            return clear_history(chat_history)

        submit_button.click(respond, [msg, chatbot, whether_rag], [msg, chatbot])
        clear_button.click(clear_chat, chatbot, chatbot)
    

    with gr.Tab("æ—…è¡Œæ™ºèƒ½æ–‡æ¡ˆç”Ÿæˆ"):
        warning_html_code = """
                <div class="hint" style="text-align: center;background-color: rgba(255, 255, 0, 0.15); padding: 10px; margin: 10px; border-radius: 5px; border: 1px solid #ffcc00;">
                    <p>ğŸ± æ¬¢è¿æ¥åˆ°LvBanæ—…æ¸¸åŠ©æ‰‹ï¼Œæ ¹æ®ä½ éšæ‰‹æ‹çš„ç…§ç‰‡ï¼Œä¸Šä¼ åˆ°è¯¥åº”ç”¨ï¼Œè‡ªåŠ¨ç”Ÿæˆä½ æƒ³è¦çš„æ–‡æ¡ˆé£æ ¼æ¨¡å¼ï¼ˆæœ‹å‹åœˆã€å°çº¢ä¹¦ã€æŠ–éŸ³ã€å¾®åšï¼‰ï¼Œç„¶ååˆ†äº«ç»™å¤§å®¶ï¼Œä¸€èµ·äº«å—æ—…æ¸¸æ„‰å¿«ã€‚</p>
                    <p>ç›¸å…³åœ°å€: <a href="https://challenge.xfyun.cn/h5/xinghuo?ch=dwm618">æ¯”èµ›åœ°å€</a>ã€<a href="https://github.com/yaosenJ/LvBanGPT">é¡¹ç›®åœ°å€</a></p>
                </div>
                """
        gr.HTML(warning_html_code)
        with gr.Row():
            image_input = gr.Image(type="pil", label="ä¸Šä¼ å›¾åƒ")
            style_dropdown = gr.Dropdown(choices=style_options, label="é€‰æ‹©é£æ ¼æ¨¡å¼", value="æœ‹å‹åœˆ")
            audio_output = gr.Audio(label="éŸ³é¢‘æ’­æ”¾", interactive=False, visible=True)

        with gr.Column():
            generate_button = gr.Button("ç”Ÿæˆæ–‡æ¡ˆ", visible=True)
            generated_text = gr.Textbox(label="ç”Ÿæˆçš„æ–‡æ¡ˆ", visible=True)

        generate_button.click(on_generate_click, inputs=[image_input, style_dropdown], outputs=[generated_text])
        convert_button = gr.Button("å°†æ–‡æ¡ˆè½¬ä¸ºè¯­éŸ³", visible=True)
        convert_button.click(on_convert_click, inputs=[generated_text], outputs=[audio_output])



if __name__ == "__main__":
    demo.queue().launch(share=True)


